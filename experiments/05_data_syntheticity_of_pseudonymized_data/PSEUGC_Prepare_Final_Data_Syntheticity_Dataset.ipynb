{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d89dfdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import glob\n",
    "import os\n",
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from __future__ import annotations\n",
    "from codealltag_data_processor_v2025 import CodealltagDataProcessor\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pandas import DataFrame\n",
    "from pandas.core.series import Series\n",
    "from tqdm import tqdm\n",
    "from typing import Any, Dict, Generator, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8aa0cbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdp_2022 = CodealltagDataProcessor(data_version='20220513', config_path=['codealltag_data_processor.yml'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9367f625",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv('data_syntheticity_dataset_3500_ss.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcda5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['CITY', 'DATE', 'EMAIL', 'FAMILY', 'FEMALE', 'MALE', 'ORG', 'PHONE', 'STREET', 'STREETNO', 'UFID', 'URL', 'USER', 'ZIP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0e3999f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_p75 = sample_df[(sample_df.L318BPOS > 0.75) & (sample_df.G29BPOS > 0.75)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d09c1c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df_p75.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d6eb454",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1759"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sample_df_p75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f94cf07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FilePath', 'OT', 'OA', 'OTT', 'OTTL', 'MT5O', 'MT5PT', 'MT5PA',\n",
       "       'MT5PTT', 'MT5PTTL', 'L318BPO', 'L318BPOS', 'G29BPO', 'G29BPOS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df_p75.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "559af781",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_pseudonymized_text_with_llama_and_gemma_output(df: DataFrame, \n",
    "                                                           idx: int, \n",
    "                                                           cdp: CodealltagDataProcessor) -> Dict[str, Tuple]:\n",
    "    \n",
    "    row: Series = df.iloc[idx]\n",
    "    orig_text: str = row.OT\n",
    "    l318b_output: str = row.L318BPO\n",
    "    l318b_adf: DataFrame = cdp.get_annotation_df_with_input_text_and_predicted_text(orig_text, l318b_output, labels)\n",
    "    l318b_pt: str = cdp.get_pseudonymized_text(orig_text, l318b_adf)\n",
    "    l318b_ptt: str = \" \".join(cdp.tokenize_with_somajo(l318b_pt))\n",
    "    g29b_output: str = row.G29BPO\n",
    "    g29b_adf: DataFrame = cdp.get_annotation_df_with_input_text_and_predicted_text(orig_text, g29b_output, labels)\n",
    "    g29b_pt: str = cdp.get_pseudonymized_text(orig_text, g29b_adf)\n",
    "    g29b_ptt: str = \" \".join(cdp.tokenize_with_somajo(g29b_pt))\n",
    "    output_tuple = (\n",
    "        row.FilePath,\n",
    "        l318b_adf.to_dict(),\n",
    "        l318b_pt,\n",
    "        l318b_ptt,\n",
    "        g29b_adf.to_dict(),\n",
    "        g29b_pt,\n",
    "        g29b_ptt\n",
    "    )\n",
    "    return {row.FilePath: output_tuple}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21dcb89a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_pseudonymized_text_with_llama_and_gemma_output(max_workers: int = 10) -> Generator[Dict[str, Tuple]]:\n",
    "    with tqdm(total=len(sample_df_p75), smoothing=0) as progress_bar:\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = [\n",
    "                executor.submit(prepare_pseudonymized_text_with_llama_and_gemma_output, sample_df_p75, idx, cdp_2022)\n",
    "                for idx in range(0, len(sample_df_p75))\n",
    "            ]\n",
    "            for future in as_completed(futures):\n",
    "                progress_bar.update(1)\n",
    "                yield future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96086710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1759/1759 [08:24<00:00,  3.49it/s]\n"
     ]
    }
   ],
   "source": [
    "merged_dict: Dict[str, Tuple] = {}\n",
    "for result in collect_pseudonymized_text_with_llama_and_gemma_output():\n",
    "    merged_dict.update(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a037f9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5523/1201539308.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df_p75[\"L318BPA\"] = sample_df_p75[\"FilePath\"].map(lambda fp: merged_dict[fp][1])\n",
      "/tmp/ipykernel_5523/1201539308.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df_p75[\"L318BPT\"] = sample_df_p75[\"FilePath\"].map(lambda fp: merged_dict[fp][2])\n",
      "/tmp/ipykernel_5523/1201539308.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df_p75[\"L318BPTT\"] = sample_df_p75[\"FilePath\"].map(lambda fp: merged_dict[fp][3])\n",
      "/tmp/ipykernel_5523/1201539308.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df_p75[\"G29BPA\"] = sample_df_p75[\"FilePath\"].map(lambda fp: merged_dict[fp][4])\n",
      "/tmp/ipykernel_5523/1201539308.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df_p75[\"G29BPT\"] = sample_df_p75[\"FilePath\"].map(lambda fp: merged_dict[fp][5])\n",
      "/tmp/ipykernel_5523/1201539308.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  sample_df_p75[\"G29BPTT\"] = sample_df_p75[\"FilePath\"].map(lambda fp: merged_dict[fp][6])\n"
     ]
    }
   ],
   "source": [
    "sample_df_p75[\"L318BPA\"] = sample_df_p75[\"FilePath\"].map(lambda fp: merged_dict[fp][1])\n",
    "sample_df_p75[\"L318BPT\"] = sample_df_p75[\"FilePath\"].map(lambda fp: merged_dict[fp][2])\n",
    "sample_df_p75[\"L318BPTT\"] = sample_df_p75[\"FilePath\"].map(lambda fp: merged_dict[fp][3])\n",
    "sample_df_p75[\"G29BPA\"] = sample_df_p75[\"FilePath\"].map(lambda fp: merged_dict[fp][4])\n",
    "sample_df_p75[\"G29BPT\"] = sample_df_p75[\"FilePath\"].map(lambda fp: merged_dict[fp][5])\n",
    "sample_df_p75[\"G29BPTT\"] = sample_df_p75[\"FilePath\"].map(lambda fp: merged_dict[fp][6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "107a8620",
   "metadata": {},
   "outputs": [],
   "source": [
    "pseud_text_df = sample_df_p75.sample(n=1500, random_state=cdp_2022.get_random_seed())\n",
    "pseud_text_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e17b0080",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FilePath</th>\n",
       "      <th>OT</th>\n",
       "      <th>OA</th>\n",
       "      <th>OTT</th>\n",
       "      <th>OTTL</th>\n",
       "      <th>MT5O</th>\n",
       "      <th>MT5PT</th>\n",
       "      <th>MT5PA</th>\n",
       "      <th>MT5PTT</th>\n",
       "      <th>MT5PTTL</th>\n",
       "      <th>L318BPO</th>\n",
       "      <th>L318BPOS</th>\n",
       "      <th>G29BPO</th>\n",
       "      <th>G29BPOS</th>\n",
       "      <th>L318BPA</th>\n",
       "      <th>L318BPT</th>\n",
       "      <th>L318BPTT</th>\n",
       "      <th>G29BPA</th>\n",
       "      <th>G29BPT</th>\n",
       "      <th>G29BPTT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CodEAlltag_pXL_MOVIES/1-/18-/184741.txt</td>\n",
       "      <td>On Wed, 19 Sep 1998 13:10:08 +0200, Hilda Regg...</td>\n",
       "      <td>{'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3', 3: 'T...</td>\n",
       "      <td>On Wed , 19 Sep 1998 13:10:08 +0200 , Hilda Re...</td>\n",
       "      <td>On O\\nWed O\\n, O\\n19 B-DATE\\nSep I-DATE\\n1998 ...</td>\n",
       "      <td>DATE: 19 Sep 1998 **17 Okt 1999**; FEMALE: Hil...</td>\n",
       "      <td>On Wed, 17 Okt 1999 13:10:08 +0200, Verna Aman...</td>\n",
       "      <td>{'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3', 3: 'T...</td>\n",
       "      <td>On Wed , 17 Okt 1999 13:10:08 +0200 , Verna Am...</td>\n",
       "      <td>On O\\nWed O\\n, O\\n17 B-DATE\\nOkt I-DATE\\n1999 ...</td>\n",
       "      <td>DATE: 19 Sep 1998 **23 Feb 2002**; FEMALE: Hil...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>------------------\\nDATE: 19 Sep 1998 **07 Oct...</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>{'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3', 3: 'T...</td>\n",
       "      <td>On Wed, 23 Feb 2002 13:10:08 +0200, Marieke Ri...</td>\n",
       "      <td>On Wed , 23 Feb 2002 13:10:08 +0200 , Marieke ...</td>\n",
       "      <td>{'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3', 3: 'T...</td>\n",
       "      <td>On Wed, 07 Oct 2023 13:10:08 +0200, Brunhilde ...</td>\n",
       "      <td>On Wed , 07 Oct 2023 13:10:08 +0200 , Brunhild...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CodEAlltag_pXL_TEENS/1-/16-/168935.txt</td>\n",
       "      <td>Am 15 Jan 2000 12:32:00 +0100, schrieb rcmmoc@...</td>\n",
       "      <td>{'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3', 3: 'T...</td>\n",
       "      <td>Am 15 Jan 2000 12:32:00 +0100 , schrieb rcmmoc...</td>\n",
       "      <td>Am O\\n15 B-DATE\\nJan I-DATE\\n2000 I-DATE\\n12:3...</td>\n",
       "      <td>DATE: 15 Jan 2000 **23 Nov 1999**; EMAIL: rcmm...</td>\n",
       "      <td>Am 23 Nov 1999 12:32:00 +0100, schrieb jthzr@j...</td>\n",
       "      <td>{'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3', 3: 'T...</td>\n",
       "      <td>Am 23 Nov 1999 12:32:00 +0100 , schrieb jthzr@...</td>\n",
       "      <td>Am O\\n23 B-DATE\\nNov I-DATE\\n1999 I-DATE\\n12:3...</td>\n",
       "      <td>DATE: 15 Jan 2000 **11. 04. 98**; MALE: Michae...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-----------------\\nDATE: 15 Jan 2000 **18 Dec ...</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>{'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3', 3: 'T...</td>\n",
       "      <td>Am 11. 04. 98 12:32:00 +0100, schrieb rcmmoc@h...</td>\n",
       "      <td>Am 11. 04. 98 12:32:00 +0100 , schrieb rcmmoc@...</td>\n",
       "      <td>{'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3', 3: 'T...</td>\n",
       "      <td>Am 18 Dec 2003 12:32:00 +0100, schrieb rcmmoc@...</td>\n",
       "      <td>Am 18 Dec 2003 12:32:00 +0100 , schrieb rcmmoc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CodEAlltag_pXL_TEENS/7-/73011.txt</td>\n",
       "      <td>Papa Leon ist Aktiv in Newsgroups wie Klassisc...</td>\n",
       "      <td>{'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3'}, 'Lab...</td>\n",
       "      <td>Papa Leon ist Aktiv in Newsgroups wie Klassisc...</td>\n",
       "      <td>Papa O\\nLeon B-MALE\\nist O\\nAktiv O\\nin O\\nNew...</td>\n",
       "      <td>MALE: Leon **Beat**; PHONE: 68397-410038 **379...</td>\n",
       "      <td>Papa Beat ist Aktiv in Newsgroups wie Klassisc...</td>\n",
       "      <td>{'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3'}, 'Lab...</td>\n",
       "      <td>Papa Beat ist Aktiv in Newsgroups wie Klassisc...</td>\n",
       "      <td>Papa O\\nBeat B-MALE\\nist O\\nAktiv O\\nin O\\nNew...</td>\n",
       "      <td>MALE: Leon **Gerhard**; CITY: Newsgroups like ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>OUTPUT\\n-------\\nMALE: Leon **Gerhard**; CITY:...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>{'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3'}, 'Lab...</td>\n",
       "      <td>Papa Gerhard ist Aktiv in Newsgroups wie Klass...</td>\n",
       "      <td>Papa Gerhard ist Aktiv in Newsgroups wie Klass...</td>\n",
       "      <td>{'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3', 3: 'T...</td>\n",
       "      <td>Papa Gerhard ist Aktiv in Fichtenwald wie Klas...</td>\n",
       "      <td>Papa Gerhard ist Aktiv in Fichtenwald wie Klas...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  FilePath  \\\n",
       "0  CodEAlltag_pXL_MOVIES/1-/18-/184741.txt   \n",
       "1   CodEAlltag_pXL_TEENS/1-/16-/168935.txt   \n",
       "2        CodEAlltag_pXL_TEENS/7-/73011.txt   \n",
       "\n",
       "                                                  OT  \\\n",
       "0  On Wed, 19 Sep 1998 13:10:08 +0200, Hilda Regg...   \n",
       "1  Am 15 Jan 2000 12:32:00 +0100, schrieb rcmmoc@...   \n",
       "2  Papa Leon ist Aktiv in Newsgroups wie Klassisc...   \n",
       "\n",
       "                                                  OA  \\\n",
       "0  {'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3', 3: 'T...   \n",
       "1  {'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3', 3: 'T...   \n",
       "2  {'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3'}, 'Lab...   \n",
       "\n",
       "                                                 OTT  \\\n",
       "0  On Wed , 19 Sep 1998 13:10:08 +0200 , Hilda Re...   \n",
       "1  Am 15 Jan 2000 12:32:00 +0100 , schrieb rcmmoc...   \n",
       "2  Papa Leon ist Aktiv in Newsgroups wie Klassisc...   \n",
       "\n",
       "                                                OTTL  \\\n",
       "0  On O\\nWed O\\n, O\\n19 B-DATE\\nSep I-DATE\\n1998 ...   \n",
       "1  Am O\\n15 B-DATE\\nJan I-DATE\\n2000 I-DATE\\n12:3...   \n",
       "2  Papa O\\nLeon B-MALE\\nist O\\nAktiv O\\nin O\\nNew...   \n",
       "\n",
       "                                                MT5O  \\\n",
       "0  DATE: 19 Sep 1998 **17 Okt 1999**; FEMALE: Hil...   \n",
       "1  DATE: 15 Jan 2000 **23 Nov 1999**; EMAIL: rcmm...   \n",
       "2  MALE: Leon **Beat**; PHONE: 68397-410038 **379...   \n",
       "\n",
       "                                               MT5PT  \\\n",
       "0  On Wed, 17 Okt 1999 13:10:08 +0200, Verna Aman...   \n",
       "1  Am 23 Nov 1999 12:32:00 +0100, schrieb jthzr@j...   \n",
       "2  Papa Beat ist Aktiv in Newsgroups wie Klassisc...   \n",
       "\n",
       "                                               MT5PA  \\\n",
       "0  {'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3', 3: 'T...   \n",
       "1  {'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3', 3: 'T...   \n",
       "2  {'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3'}, 'Lab...   \n",
       "\n",
       "                                              MT5PTT  \\\n",
       "0  On Wed , 17 Okt 1999 13:10:08 +0200 , Verna Am...   \n",
       "1  Am 23 Nov 1999 12:32:00 +0100 , schrieb jthzr@...   \n",
       "2  Papa Beat ist Aktiv in Newsgroups wie Klassisc...   \n",
       "\n",
       "                                             MT5PTTL  \\\n",
       "0  On O\\nWed O\\n, O\\n17 B-DATE\\nOkt I-DATE\\n1999 ...   \n",
       "1  Am O\\n23 B-DATE\\nNov I-DATE\\n1999 I-DATE\\n12:3...   \n",
       "2  Papa O\\nBeat B-MALE\\nist O\\nAktiv O\\nin O\\nNew...   \n",
       "\n",
       "                                             L318BPO  L318BPOS  \\\n",
       "0  DATE: 19 Sep 1998 **23 Feb 2002**; FEMALE: Hil...       1.0   \n",
       "1  DATE: 15 Jan 2000 **11. 04. 98**; MALE: Michae...       1.0   \n",
       "2  MALE: Leon **Gerhard**; CITY: Newsgroups like ...       1.0   \n",
       "\n",
       "                                              G29BPO   G29BPOS  \\\n",
       "0  ------------------\\nDATE: 19 Sep 1998 **07 Oct...  0.800000   \n",
       "1  -----------------\\nDATE: 15 Jan 2000 **18 Dec ...  0.857143   \n",
       "2  OUTPUT\\n-------\\nMALE: Leon **Gerhard**; CITY:...  1.000000   \n",
       "\n",
       "                                             L318BPA  \\\n",
       "0  {'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3', 3: 'T...   \n",
       "1  {'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3', 3: 'T...   \n",
       "2  {'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3'}, 'Lab...   \n",
       "\n",
       "                                             L318BPT  \\\n",
       "0  On Wed, 23 Feb 2002 13:10:08 +0200, Marieke Ri...   \n",
       "1  Am 11. 04. 98 12:32:00 +0100, schrieb rcmmoc@h...   \n",
       "2  Papa Gerhard ist Aktiv in Newsgroups wie Klass...   \n",
       "\n",
       "                                            L318BPTT  \\\n",
       "0  On Wed , 23 Feb 2002 13:10:08 +0200 , Marieke ...   \n",
       "1  Am 11. 04. 98 12:32:00 +0100 , schrieb rcmmoc@...   \n",
       "2  Papa Gerhard ist Aktiv in Newsgroups wie Klass...   \n",
       "\n",
       "                                              G29BPA  \\\n",
       "0  {'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3', 3: 'T...   \n",
       "1  {'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3', 3: 'T...   \n",
       "2  {'Token_ID': {0: 'T1', 1: 'T2', 2: 'T3', 3: 'T...   \n",
       "\n",
       "                                              G29BPT  \\\n",
       "0  On Wed, 07 Oct 2023 13:10:08 +0200, Brunhilde ...   \n",
       "1  Am 18 Dec 2003 12:32:00 +0100, schrieb rcmmoc@...   \n",
       "2  Papa Gerhard ist Aktiv in Fichtenwald wie Klas...   \n",
       "\n",
       "                                             G29BPTT  \n",
       "0  On Wed , 07 Oct 2023 13:10:08 +0200 , Brunhild...  \n",
       "1  Am 18 Dec 2003 12:32:00 +0100 , schrieb rcmmoc...  \n",
       "2  Papa Gerhard ist Aktiv in Fichtenwald wie Klas...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pseud_text_df.head(n=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82503752",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_syntheticity_dataset(pseud_text_df: DataFrame, model: str):\n",
    "    tuples: List[Tuple] = list()\n",
    "    for idx_o, row_o in pseud_text_df.iterrows():\n",
    "        tuples.append((row_o.FilePath, row_o.OT, row_o.OTT, \"ORIG\"))\n",
    "    for idx_p, row_p in pseud_text_df.iterrows():\n",
    "        tuples.append((row_p.FilePath, row_p[f'{model}PT'], row_p[f'{model}PTT'], \"PSEUD\"))\n",
    "    df = pd.DataFrame(tuples, columns=[\"FilePath\", \"Text\", \"TextTokenized\", \"Type\"])\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    df.to_csv(f\"data_syntheticity_dataset_3000_{model}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e6c0e943",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data_syntheticity_dataset(pseud_text_df, model=\"MT5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d10aa185",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data_syntheticity_dataset(pseud_text_df, model=\"L318B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f305c23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_data_syntheticity_dataset(pseud_text_df, model=\"G29B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5006a742",
   "metadata": {},
   "outputs": [],
   "source": [
    "mT5_dataset = pd.read_csv(\"data_syntheticity_dataset_3000_MT5.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cbc89a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "l318b_dataset = pd.read_csv(\"data_syntheticity_dataset_3000_L318B.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "18aece6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g29b_dataset = pd.read_csv(\"data_syntheticity_dataset_3000_G29B.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ec8e28d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Wed, 19 Sep 1998 13:10:08 +0200, Hilda Reggentin\n",
      "\n",
      "Der sogenannte \"Missionar\" wartet noch ein wenig, in etwa bis die\n",
      "nächste FAQ mit den entsprechenden Verweisen bzgl. drfm und Kritiken\n",
      "gepostet wurde (damit ihn niemand wie hier geschehen ohne weiteres\n",
      "anpflaumen kann, weil er seinen überlangen Krempel nicht in drfk\n",
      "postet), um dann wieder was in drfm zu veröffentlichen. Elsa\n",
      "Äußerungen waren hierfür der endgültige Auslöser. Nennt es meinetwegen\n",
      "eine Trotzreaktion. EOT.\n",
      "\n",
      "cu,\n",
      "  Luis\n",
      "\n",
      "P.S.: Wahrscheinlich wird es \"Lost Highway\" oder die\n",
      "144-Minuten-Fassung von \"The Shining\". Ich kann mich nicht\n",
      "entscheiden.\n"
     ]
    }
   ],
   "source": [
    "print(mT5_dataset.iloc[0].Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93f6c57b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Wed, 17 Okt 1999 13:10:08 +0200, Verna Amann\n",
      "\n",
      "Der sogenannte \"Missionar\" wartet noch ein wenig, in etwa bis die\n",
      "nächste FAQ mit den entsprechenden Verweisen bzgl. drfm und Kritiken\n",
      "gepostet wurde (damit ihn niemand wie hier geschehen ohne weiteres\n",
      "anpflaumen kann, weil er seinen überlangen Krempel nicht in drfk\n",
      "postet), um dann wieder was in drfm zu veröffentlichen. Lutz\n",
      "Äußerungen waren hierfür der endgültige Auslöser. Nennt es meinetwegen\n",
      "eine Trotzreaktion. EOT.\n",
      "\n",
      "cu,\n",
      "  Lars\n",
      "\n",
      "P.S.: Wahrscheinlich wird es \"Lost Highway\" oder die\n",
      "144-Minuten-Fassung von \"The Shining\". Ich kann mich nicht\n",
      "entscheiden.\n"
     ]
    }
   ],
   "source": [
    "print(mT5_dataset.iloc[1500].Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e4b907f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Wed, 19 Sep 1998 13:10:08 +0200, Hilda Reggentin\n",
      "\n",
      "Der sogenannte \"Missionar\" wartet noch ein wenig, in etwa bis die\n",
      "nächste FAQ mit den entsprechenden Verweisen bzgl. drfm und Kritiken\n",
      "gepostet wurde (damit ihn niemand wie hier geschehen ohne weiteres\n",
      "anpflaumen kann, weil er seinen überlangen Krempel nicht in drfk\n",
      "postet), um dann wieder was in drfm zu veröffentlichen. Elsa\n",
      "Äußerungen waren hierfür der endgültige Auslöser. Nennt es meinetwegen\n",
      "eine Trotzreaktion. EOT.\n",
      "\n",
      "cu,\n",
      "  Luis\n",
      "\n",
      "P.S.: Wahrscheinlich wird es \"Lost Highway\" oder die\n",
      "144-Minuten-Fassung von \"The Shining\". Ich kann mich nicht\n",
      "entscheiden.\n"
     ]
    }
   ],
   "source": [
    "print(l318b_dataset.iloc[0].Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "970f3af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Wed, 23 Feb 2002 13:10:08 +0200, Marieke Riemann\n",
      "\n",
      "Der sogenannte \"Missionar\" wartet noch ein wenig, in etwa bis die\n",
      "nächste FAQ mit den entsprechenden Verweisen bzgl. drfm und Kritiken\n",
      "gepostet wurde (damit ihn niemand wie hier geschehen ohne weiteres\n",
      "anpflaumen kann, weil er seinen überlangen Krempel nicht in drfk\n",
      "postet), um dann wieder was in drfm zu veröffentlichen. Elsa\n",
      "Äußerungen waren hierfür der endgültige Auslöser. Nennt es meinetwegen\n",
      "eine Trotzreaktion. EOT.\n",
      "\n",
      "cu,\n",
      "  Gerson\n",
      "\n",
      "P.S.: Wahrscheinlich wird es \"Lost Highway\" oder die\n",
      "144-Minuten-Fassung von \"The Shining\". Ich kann mich nicht\n",
      "entscheiden.\n"
     ]
    }
   ],
   "source": [
    "print(l318b_dataset.iloc[1500].Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e4c1c8e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Wed, 19 Sep 1998 13:10:08 +0200, Hilda Reggentin\n",
      "\n",
      "Der sogenannte \"Missionar\" wartet noch ein wenig, in etwa bis die\n",
      "nächste FAQ mit den entsprechenden Verweisen bzgl. drfm und Kritiken\n",
      "gepostet wurde (damit ihn niemand wie hier geschehen ohne weiteres\n",
      "anpflaumen kann, weil er seinen überlangen Krempel nicht in drfk\n",
      "postet), um dann wieder was in drfm zu veröffentlichen. Elsa\n",
      "Äußerungen waren hierfür der endgültige Auslöser. Nennt es meinetwegen\n",
      "eine Trotzreaktion. EOT.\n",
      "\n",
      "cu,\n",
      "  Luis\n",
      "\n",
      "P.S.: Wahrscheinlich wird es \"Lost Highway\" oder die\n",
      "144-Minuten-Fassung von \"The Shining\". Ich kann mich nicht\n",
      "entscheiden.\n"
     ]
    }
   ],
   "source": [
    "print(g29b_dataset.iloc[0].Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "95c3d321",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On Wed, 07 Oct 2023 13:10:08 +0200, Brunhilde Schröder\n",
      "\n",
      "Der sogenannte \"Missionar\" wartet noch ein wenig, in etwa bis die\n",
      "nächste FAQ mit den entsprechenden Verweisen bzgl. drfm und Kritiken\n",
      "gepostet wurde (damit ihn niemand wie hier geschehen ohne weiteres\n",
      "anpflaumen kann, weil er seinen überlangen Krempel nicht in drfk\n",
      "postet), um dann wieder was in drfm zu veröffentlichen. Elsa\n",
      "Äußerungen waren hierfür der endgültige Auslöser. Nennt es meinetwegen\n",
      "eine Trotzreaktion. EOT.\n",
      "\n",
      "cu,\n",
      "  Klaus\n",
      "\n",
      "P.S.: Wahrscheinlich wird es \"Lost Highway\" oder die\n",
      "144-Minuten-Fassung von \"The Shining\". Ich kann mich nicht\n",
      "entscheiden.\n"
     ]
    }
   ],
   "source": [
    "print(g29b_dataset.iloc[1500].Text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
