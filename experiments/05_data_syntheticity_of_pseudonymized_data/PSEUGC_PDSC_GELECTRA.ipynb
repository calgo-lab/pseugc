{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d562e706",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Mar  9 02:03:40 2025       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  Tesla V100S-PCIE-32GB          On  |   00000000:81:00.0 Off |                    0 |\r\n",
      "| N/A   32C    P0             25W /  250W |       1MiB /  32768MiB |      0%      Default |\r\n",
      "|                                         |                        |                  N/A |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "|  No running processes found                                                             |\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3863314",
   "metadata": {},
   "outputs": [],
   "source": [
    "import flair\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from codealltag_data_processor_v2025 import CodealltagDataProcessor\n",
    "from flair.data import Corpus, Dictionary\n",
    "from flair.datasets import CSVClassificationCorpus\n",
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "from flair.models import TextClassifier\n",
    "from flair.nn import Model\n",
    "from flair.trainers import ModelTrainer\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40816482",
   "metadata": {},
   "outputs": [],
   "source": [
    "flair.cache_root = Path(os.path.join(*['/home', 's81481', '.flair']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0fc4264a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdp_2022 = CodealltagDataProcessor(data_version='20220513', config_path=['codealltag_data_processor.yml'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97235c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tag = \"G29B\" # \"MT5\" | \"L318B\" | \"G29B\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe06f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_flair_corpus(data_folder: Path) -> CSVClassificationCorpus:\n",
    "    \n",
    "    train_df[['TextTokenized', 'Type']].to_csv(f\"{data_folder}/train.csv\", \n",
    "                                               sep='\\t', \n",
    "                                               index=False, \n",
    "                                               header=['text', 'label'])\n",
    "    \n",
    "    dev_df[['TextTokenized', 'Type']].to_csv(f\"{data_folder}/dev.csv\", \n",
    "                                             sep='\\t', \n",
    "                                             index=False, \n",
    "                                             header=['text', 'label'])\n",
    "    \n",
    "    test_df[['TextTokenized', 'Type']].to_csv(f\"{data_folder}/test.csv\", \n",
    "                                              sep='\\t', \n",
    "                                              index=False, \n",
    "                                              header=['text', 'label'])\n",
    "    \n",
    "    column_name_map = {0: \"text\", 1: \"label\"}  \n",
    "    label_type = \"label\"\n",
    "    corpus = CSVClassificationCorpus(\n",
    "        data_folder,\n",
    "        column_name_map, \n",
    "        skip_header=True, \n",
    "        delimiter=\"\\t\",\n",
    "        label_type=label_type,\n",
    "        train_file='train.csv',\n",
    "        dev_file='dev.csv',\n",
    "        test_file='test.csv'\n",
    "    )\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea117cf0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:06:16,599 Reading data from tmp_data_dir\n",
      "2025-03-09 02:06:16,599 Train: tmp_data_dir/train.csv\n",
      "2025-03-09 02:06:16,599 Dev: tmp_data_dir/dev.csv\n",
      "2025-03-09 02:06:16,600 Test: tmp_data_dir/test.csv\n",
      "2025-03-09 02:06:16,613 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:01, 1654.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:06:17,848 Dictionary created for label 'label' with 3 values: ORIG (seen 1000 times), PSEUD (seen 1000 times)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/s81481/pseugc/lib/python3.9/site-packages/transformers/modeling_utils.py:349: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:06:26,476 tensorboard logging path is logs/PDSC_V2/GELECTRA/G29B/3K/k1\n",
      "2025-03-09 02:06:32,000 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:06:32,002 Model: \"TextClassifier(\n",
      "  (decoder): Linear(in_features=1024, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (document_embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): ElectraModel(\n",
      "      (embeddings): ElectraEmbeddings(\n",
      "        (word_embeddings): Embedding(31102, 1024, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 1024)\n",
      "        (token_type_embeddings): Embedding(2, 1024)\n",
      "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): ElectraEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-23): 24 x ElectraLayer(\n",
      "            (attention): ElectraAttention(\n",
      "              (self): ElectraSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): ElectraSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): ElectraIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): ElectraOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2025-03-09 02:06:32,003 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:06:32,003 Corpus: \"Corpus: 2000 train + 500 dev + 500 test sentences\"\n",
      "2025-03-09 02:06:32,004 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:06:32,004 Parameters:\n",
      "2025-03-09 02:06:32,004  - learning_rate: \"0.000005\"\n",
      "2025-03-09 02:06:32,004  - mini_batch_size: \"4\"\n",
      "2025-03-09 02:06:32,005  - patience: \"3\"\n",
      "2025-03-09 02:06:32,005  - anneal_factor: \"0.5\"\n",
      "2025-03-09 02:06:32,005  - max_epochs: \"10\"\n",
      "2025-03-09 02:06:32,006  - shuffle: \"True\"\n",
      "2025-03-09 02:06:32,006  - train_with_dev: \"False\"\n",
      "2025-03-09 02:06:32,006  - batch_growth_annealing: \"False\"\n",
      "2025-03-09 02:06:32,006 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:06:32,007 Model training base path: \"logs/PDSC_V2/GELECTRA/G29B/3K/k1\"\n",
      "2025-03-09 02:06:32,007 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:06:32,007 Device: cuda:0\n",
      "2025-03-09 02:06:32,008 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:06:32,008 Embeddings storage mode: none\n",
      "2025-03-09 02:06:32,008 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:06:39,700 epoch 1 - iter 50/500 - loss 0.27931744 - samples/sec: 26.37 - lr: 0.000001\n",
      "2025-03-09 02:06:47,610 epoch 1 - iter 100/500 - loss 0.19698879 - samples/sec: 26.55 - lr: 0.000001\n",
      "2025-03-09 02:06:54,982 epoch 1 - iter 150/500 - loss 0.13607035 - samples/sec: 28.46 - lr: 0.000002\n",
      "2025-03-09 02:07:02,859 epoch 1 - iter 200/500 - loss 0.10276509 - samples/sec: 26.57 - lr: 0.000002\n",
      "2025-03-09 02:07:10,192 epoch 1 - iter 250/500 - loss 0.08243254 - samples/sec: 28.63 - lr: 0.000003\n",
      "2025-03-09 02:07:17,957 epoch 1 - iter 300/500 - loss 0.17107272 - samples/sec: 26.95 - lr: 0.000003\n",
      "2025-03-09 02:07:26,062 epoch 1 - iter 350/500 - loss 0.14686250 - samples/sec: 25.80 - lr: 0.000003\n",
      "2025-03-09 02:07:33,860 epoch 1 - iter 400/500 - loss 0.12856187 - samples/sec: 26.85 - lr: 0.000004\n",
      "2025-03-09 02:07:41,878 epoch 1 - iter 450/500 - loss 0.11431144 - samples/sec: 26.09 - lr: 0.000005\n",
      "2025-03-09 02:07:48,933 epoch 1 - iter 500/500 - loss 0.10290287 - samples/sec: 29.77 - lr: 0.000005\n",
      "2025-03-09 02:07:49,180 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:07:49,180 EPOCH 1 done: loss 0.1029 - lr 0.000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 23.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:07:54,408 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:07:54,417 DEV : loss 1.0070340633392334 - f1-score (micro avg)  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:07:54,673 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:07:59,914 saving best model\n",
      "2025-03-09 02:08:06,394 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:08:14,151 epoch 2 - iter 50/500 - loss 0.32939278 - samples/sec: 26.18 - lr: 0.000005\n",
      "2025-03-09 02:08:21,789 epoch 2 - iter 100/500 - loss 0.25690874 - samples/sec: 27.44 - lr: 0.000005\n",
      "2025-03-09 02:08:29,533 epoch 2 - iter 150/500 - loss 0.23036828 - samples/sec: 27.08 - lr: 0.000005\n",
      "2025-03-09 02:08:37,524 epoch 2 - iter 200/500 - loss 0.21800934 - samples/sec: 26.19 - lr: 0.000005\n",
      "2025-03-09 02:08:44,919 epoch 2 - iter 250/500 - loss 0.21079357 - samples/sec: 28.36 - lr: 0.000005\n",
      "2025-03-09 02:08:52,054 epoch 2 - iter 300/500 - loss 0.20649138 - samples/sec: 29.45 - lr: 0.000005\n",
      "2025-03-09 02:08:59,570 epoch 2 - iter 350/500 - loss 0.20188078 - samples/sec: 27.89 - lr: 0.000005\n",
      "2025-03-09 02:09:07,451 epoch 2 - iter 400/500 - loss 0.19765101 - samples/sec: 26.56 - lr: 0.000005\n",
      "2025-03-09 02:09:15,009 epoch 2 - iter 450/500 - loss 0.19327123 - samples/sec: 27.72 - lr: 0.000005\n",
      "2025-03-09 02:09:22,834 epoch 2 - iter 500/500 - loss 0.18771258 - samples/sec: 26.77 - lr: 0.000004\n",
      "2025-03-09 02:09:23,203 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:09:23,203 EPOCH 2 done: loss 0.1877 - lr 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 23.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:09:28,689 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:09:28,697 DEV : loss 0.1654728800058365 - f1-score (micro avg)  0.678\n",
      "2025-03-09 02:09:28,958 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:09:34,424 saving best model\n",
      "2025-03-09 02:09:39,842 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:09:47,729 epoch 3 - iter 50/500 - loss 0.12073174 - samples/sec: 25.73 - lr: 0.000004\n",
      "2025-03-09 02:09:56,020 epoch 3 - iter 100/500 - loss 0.12651123 - samples/sec: 25.51 - lr: 0.000004\n",
      "2025-03-09 02:10:03,175 epoch 3 - iter 150/500 - loss 0.12101520 - samples/sec: 29.34 - lr: 0.000004\n",
      "2025-03-09 02:10:10,861 epoch 3 - iter 200/500 - loss 0.11591819 - samples/sec: 27.25 - lr: 0.000004\n",
      "2025-03-09 02:10:18,486 epoch 3 - iter 250/500 - loss 0.11552274 - samples/sec: 27.52 - lr: 0.000004\n",
      "2025-03-09 02:10:26,337 epoch 3 - iter 300/500 - loss 0.11408100 - samples/sec: 26.65 - lr: 0.000004\n",
      "2025-03-09 02:10:34,139 epoch 3 - iter 350/500 - loss 0.11150803 - samples/sec: 26.80 - lr: 0.000004\n",
      "2025-03-09 02:10:42,020 epoch 3 - iter 400/500 - loss 0.11478091 - samples/sec: 26.57 - lr: 0.000004\n",
      "2025-03-09 02:10:49,413 epoch 3 - iter 450/500 - loss 0.11217386 - samples/sec: 28.40 - lr: 0.000004\n",
      "2025-03-09 02:10:57,086 epoch 3 - iter 500/500 - loss 0.11185269 - samples/sec: 27.30 - lr: 0.000004\n",
      "2025-03-09 02:10:57,332 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:10:57,332 EPOCH 3 done: loss 0.1119 - lr 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 23.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:11:02,915 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:11:02,922 DEV : loss 0.13278734683990479 - f1-score (micro avg)  0.808\n",
      "2025-03-09 02:11:03,460 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:11:08,503 saving best model\n",
      "2025-03-09 02:11:13,695 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:11:21,056 epoch 4 - iter 50/500 - loss 0.08089427 - samples/sec: 27.56 - lr: 0.000004\n",
      "2025-03-09 02:11:28,706 epoch 4 - iter 100/500 - loss 0.08241286 - samples/sec: 27.40 - lr: 0.000004\n",
      "2025-03-09 02:11:36,589 epoch 4 - iter 150/500 - loss 0.06939714 - samples/sec: 26.58 - lr: 0.000004\n",
      "2025-03-09 02:11:44,497 epoch 4 - iter 200/500 - loss 0.07871837 - samples/sec: 26.50 - lr: 0.000004\n",
      "2025-03-09 02:11:52,643 epoch 4 - iter 250/500 - loss 0.07970293 - samples/sec: 27.73 - lr: 0.000004\n",
      "2025-03-09 02:12:00,567 epoch 4 - iter 300/500 - loss 0.08215805 - samples/sec: 26.42 - lr: 0.000004\n",
      "2025-03-09 02:12:08,101 epoch 4 - iter 350/500 - loss 0.08047960 - samples/sec: 27.83 - lr: 0.000004\n",
      "2025-03-09 02:12:16,172 epoch 4 - iter 400/500 - loss 0.07827948 - samples/sec: 25.90 - lr: 0.000003\n",
      "2025-03-09 02:12:23,958 epoch 4 - iter 450/500 - loss 0.07524209 - samples/sec: 26.89 - lr: 0.000003\n",
      "2025-03-09 02:12:32,027 epoch 4 - iter 500/500 - loss 0.07243963 - samples/sec: 25.92 - lr: 0.000003\n",
      "2025-03-09 02:12:32,278 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:12:32,278 EPOCH 4 done: loss 0.0724 - lr 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 23.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:12:37,550 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:12:37,558 DEV : loss 0.21050098538398743 - f1-score (micro avg)  0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:12:38,127 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:12:43,252 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:12:51,099 epoch 5 - iter 50/500 - loss 0.02374298 - samples/sec: 25.86 - lr: 0.000003\n",
      "2025-03-09 02:12:58,738 epoch 5 - iter 100/500 - loss 0.03177641 - samples/sec: 27.93 - lr: 0.000003\n",
      "2025-03-09 02:13:05,956 epoch 5 - iter 150/500 - loss 0.03555310 - samples/sec: 29.08 - lr: 0.000003\n",
      "2025-03-09 02:13:14,278 epoch 5 - iter 200/500 - loss 0.03235690 - samples/sec: 25.10 - lr: 0.000003\n",
      "2025-03-09 02:13:21,637 epoch 5 - iter 250/500 - loss 0.03199446 - samples/sec: 28.51 - lr: 0.000003\n",
      "2025-03-09 02:13:29,206 epoch 5 - iter 300/500 - loss 0.03452832 - samples/sec: 27.68 - lr: 0.000003\n",
      "2025-03-09 02:13:37,209 epoch 5 - iter 350/500 - loss 0.03903043 - samples/sec: 26.11 - lr: 0.000003\n",
      "2025-03-09 02:13:44,621 epoch 5 - iter 400/500 - loss 0.04262837 - samples/sec: 28.32 - lr: 0.000003\n",
      "2025-03-09 02:13:52,628 epoch 5 - iter 450/500 - loss 0.04511317 - samples/sec: 26.13 - lr: 0.000003\n",
      "2025-03-09 02:14:00,513 epoch 5 - iter 500/500 - loss 0.04731832 - samples/sec: 26.56 - lr: 0.000003\n",
      "2025-03-09 02:14:00,837 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:14:00,837 EPOCH 5 done: loss 0.0473 - lr 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 23.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:14:06,098 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:14:06,106 DEV : loss 0.20196621119976044 - f1-score (micro avg)  0.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:14:06,666 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:14:11,705 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:14:18,864 epoch 6 - iter 50/500 - loss 0.00673004 - samples/sec: 28.33 - lr: 0.000003\n",
      "2025-03-09 02:14:26,366 epoch 6 - iter 100/500 - loss 0.01527146 - samples/sec: 27.95 - lr: 0.000003\n",
      "2025-03-09 02:14:34,166 epoch 6 - iter 150/500 - loss 0.02118177 - samples/sec: 26.85 - lr: 0.000003\n",
      "2025-03-09 02:14:41,634 epoch 6 - iter 200/500 - loss 0.02213852 - samples/sec: 28.09 - lr: 0.000003\n",
      "2025-03-09 02:14:49,306 epoch 6 - iter 250/500 - loss 0.02337053 - samples/sec: 27.45 - lr: 0.000003\n",
      "2025-03-09 02:14:57,695 epoch 6 - iter 300/500 - loss 0.02457398 - samples/sec: 24.93 - lr: 0.000002\n",
      "2025-03-09 02:15:05,539 epoch 6 - iter 350/500 - loss 0.03054396 - samples/sec: 26.69 - lr: 0.000002\n",
      "2025-03-09 02:15:13,169 epoch 6 - iter 400/500 - loss 0.03159195 - samples/sec: 27.46 - lr: 0.000002\n",
      "2025-03-09 02:15:21,445 epoch 6 - iter 450/500 - loss 0.03139742 - samples/sec: 26.19 - lr: 0.000002\n",
      "2025-03-09 02:15:28,918 epoch 6 - iter 500/500 - loss 0.03126838 - samples/sec: 28.06 - lr: 0.000002\n",
      "2025-03-09 02:15:29,165 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:15:29,165 EPOCH 6 done: loss 0.0313 - lr 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 23.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:15:34,420 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:15:34,428 DEV : loss 0.23457534611225128 - f1-score (micro avg)  0.822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:15:34,680 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:15:39,783 saving best model\n",
      "2025-03-09 02:15:45,036 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:15:51,982 epoch 7 - iter 50/500 - loss 0.01001899 - samples/sec: 29.22 - lr: 0.000002\n",
      "2025-03-09 02:15:59,599 epoch 7 - iter 100/500 - loss 0.02052981 - samples/sec: 27.49 - lr: 0.000002\n",
      "2025-03-09 02:16:07,502 epoch 7 - iter 150/500 - loss 0.02181051 - samples/sec: 26.48 - lr: 0.000002\n",
      "2025-03-09 02:16:15,601 epoch 7 - iter 200/500 - loss 0.02466200 - samples/sec: 25.83 - lr: 0.000002\n",
      "2025-03-09 02:16:23,730 epoch 7 - iter 250/500 - loss 0.02631246 - samples/sec: 25.74 - lr: 0.000002\n",
      "2025-03-09 02:16:31,633 epoch 7 - iter 300/500 - loss 0.02325173 - samples/sec: 26.47 - lr: 0.000002\n",
      "2025-03-09 02:16:39,638 epoch 7 - iter 350/500 - loss 0.02357794 - samples/sec: 26.13 - lr: 0.000002\n",
      "2025-03-09 02:16:47,233 epoch 7 - iter 400/500 - loss 0.02256261 - samples/sec: 27.61 - lr: 0.000002\n",
      "2025-03-09 02:16:54,917 epoch 7 - iter 450/500 - loss 0.02176712 - samples/sec: 27.26 - lr: 0.000002\n",
      "2025-03-09 02:17:02,210 epoch 7 - iter 500/500 - loss 0.02267339 - samples/sec: 28.81 - lr: 0.000002\n",
      "2025-03-09 02:17:02,455 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:17:02,455 EPOCH 7 done: loss 0.0227 - lr 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 23.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:17:07,717 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:17:07,725 DEV : loss 0.31262731552124023 - f1-score (micro avg)  0.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:17:07,976 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:17:13,048 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:17:20,604 epoch 8 - iter 50/500 - loss 0.00607131 - samples/sec: 26.86 - lr: 0.000002\n",
      "2025-03-09 02:17:27,833 epoch 8 - iter 100/500 - loss 0.01137895 - samples/sec: 29.42 - lr: 0.000002\n",
      "2025-03-09 02:17:35,915 epoch 8 - iter 150/500 - loss 0.01864725 - samples/sec: 25.87 - lr: 0.000002\n",
      "2025-03-09 02:17:44,482 epoch 8 - iter 200/500 - loss 0.01928553 - samples/sec: 24.35 - lr: 0.000001\n",
      "2025-03-09 02:17:52,205 epoch 8 - iter 250/500 - loss 0.01694365 - samples/sec: 27.12 - lr: 0.000001\n",
      "2025-03-09 02:18:00,353 epoch 8 - iter 300/500 - loss 0.01536073 - samples/sec: 25.68 - lr: 0.000001\n",
      "2025-03-09 02:18:07,627 epoch 8 - iter 350/500 - loss 0.01372281 - samples/sec: 28.86 - lr: 0.000001\n",
      "2025-03-09 02:18:15,383 epoch 8 - iter 400/500 - loss 0.01339059 - samples/sec: 27.00 - lr: 0.000001\n",
      "2025-03-09 02:18:23,546 epoch 8 - iter 450/500 - loss 0.01425493 - samples/sec: 25.61 - lr: 0.000001\n",
      "2025-03-09 02:18:30,907 epoch 8 - iter 500/500 - loss 0.01350978 - samples/sec: 29.07 - lr: 0.000001\n",
      "2025-03-09 02:18:31,153 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:18:31,154 EPOCH 8 done: loss 0.0135 - lr 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 23.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:18:36,562 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:18:36,569 DEV : loss 0.3091127574443817 - f1-score (micro avg)  0.818\n",
      "2025-03-09 02:18:36,827 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:18:41,936 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:18:49,706 epoch 9 - iter 50/500 - loss 0.01435573 - samples/sec: 27.00 - lr: 0.000001\n",
      "2025-03-09 02:18:57,220 epoch 9 - iter 100/500 - loss 0.01986344 - samples/sec: 27.91 - lr: 0.000001\n",
      "2025-03-09 02:19:04,915 epoch 9 - iter 150/500 - loss 0.01729076 - samples/sec: 27.21 - lr: 0.000001\n",
      "2025-03-09 02:19:12,942 epoch 9 - iter 200/500 - loss 0.01545313 - samples/sec: 26.05 - lr: 0.000001\n",
      "2025-03-09 02:19:20,733 epoch 9 - iter 250/500 - loss 0.01396191 - samples/sec: 26.86 - lr: 0.000001\n",
      "2025-03-09 02:19:28,570 epoch 9 - iter 300/500 - loss 0.01179952 - samples/sec: 26.69 - lr: 0.000001\n",
      "2025-03-09 02:19:36,873 epoch 9 - iter 350/500 - loss 0.01191017 - samples/sec: 25.16 - lr: 0.000001\n",
      "2025-03-09 02:19:44,494 epoch 9 - iter 400/500 - loss 0.01134523 - samples/sec: 27.50 - lr: 0.000001\n",
      "2025-03-09 02:19:52,351 epoch 9 - iter 450/500 - loss 0.01035275 - samples/sec: 26.84 - lr: 0.000001\n",
      "2025-03-09 02:20:00,092 epoch 9 - iter 500/500 - loss 0.00987226 - samples/sec: 27.07 - lr: 0.000001\n",
      "2025-03-09 02:20:00,338 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:20:00,339 EPOCH 9 done: loss 0.0099 - lr 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 23.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:20:05,621 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:20:05,629 DEV : loss 0.3255111873149872 - f1-score (micro avg)  0.82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:20:06,171 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:20:11,293 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:20:18,562 epoch 10 - iter 50/500 - loss 0.00443440 - samples/sec: 27.91 - lr: 0.000001\n",
      "2025-03-09 02:20:27,150 epoch 10 - iter 100/500 - loss 0.01078157 - samples/sec: 24.72 - lr: 0.000000\n",
      "2025-03-09 02:20:34,833 epoch 10 - iter 150/500 - loss 0.00828740 - samples/sec: 27.28 - lr: 0.000000\n",
      "2025-03-09 02:20:42,176 epoch 10 - iter 200/500 - loss 0.00707670 - samples/sec: 28.57 - lr: 0.000000\n",
      "2025-03-09 02:20:49,709 epoch 10 - iter 250/500 - loss 0.00637768 - samples/sec: 27.82 - lr: 0.000000\n",
      "2025-03-09 02:20:57,525 epoch 10 - iter 300/500 - loss 0.00995382 - samples/sec: 26.81 - lr: 0.000000\n",
      "2025-03-09 02:21:04,858 epoch 10 - iter 350/500 - loss 0.00934097 - samples/sec: 28.62 - lr: 0.000000\n",
      "2025-03-09 02:21:12,616 epoch 10 - iter 400/500 - loss 0.00944737 - samples/sec: 27.78 - lr: 0.000000\n",
      "2025-03-09 02:21:20,773 epoch 10 - iter 450/500 - loss 0.00850093 - samples/sec: 25.62 - lr: 0.000000\n",
      "2025-03-09 02:21:28,756 epoch 10 - iter 500/500 - loss 0.00900422 - samples/sec: 26.51 - lr: 0.000000\n",
      "2025-03-09 02:21:29,003 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:21:29,004 EPOCH 10 done: loss 0.0090 - lr 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 23.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:21:34,457 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:21:34,465 DEV : loss 0.3139808475971222 - f1-score (micro avg)  0.824\n",
      "2025-03-09 02:21:35,050 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:21:40,385 saving best model\n",
      "2025-03-09 02:21:46,581 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:21:46,584 loading file logs/PDSC_V2/GELECTRA/G29B/3K/k1/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 22.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:22:06,553 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:22:06,560 0.822\t0.822\t0.822\t0.822\n",
      "2025-03-09 02:22:06,561 \n",
      "Results:\n",
      "- F-score (micro) 0.822\n",
      "- F-score (macro) 0.8214\n",
      "- Accuracy 0.822\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       PSEUD     0.7885    0.8800    0.8318       250\n",
      "        ORIG     0.8643    0.7640    0.8110       250\n",
      "\n",
      "    accuracy                         0.8220       500\n",
      "   macro avg     0.8264    0.8220    0.8214       500\n",
      "weighted avg     0.8264    0.8220    0.8214       500\n",
      "\n",
      "2025-03-09 02:22:06,561 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:22:06,637 Reading data from tmp_data_dir\n",
      "2025-03-09 02:22:06,637 Train: tmp_data_dir/train.csv\n",
      "2025-03-09 02:22:06,637 Dev: tmp_data_dir/dev.csv\n",
      "2025-03-09 02:22:06,638 Test: tmp_data_dir/test.csv\n",
      "2025-03-09 02:22:06,651 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:01, 1937.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:22:07,685 Dictionary created for label 'label' with 3 values: ORIG (seen 1000 times), PSEUD (seen 1000 times)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/s81481/pseugc/lib/python3.9/site-packages/transformers/modeling_utils.py:349: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:22:20,921 tensorboard logging path is logs/PDSC_V2/GELECTRA/G29B/3K/k2\n",
      "2025-03-09 02:22:20,943 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:22:20,945 Model: \"TextClassifier(\n",
      "  (decoder): Linear(in_features=1024, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (document_embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): ElectraModel(\n",
      "      (embeddings): ElectraEmbeddings(\n",
      "        (word_embeddings): Embedding(31102, 1024, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 1024)\n",
      "        (token_type_embeddings): Embedding(2, 1024)\n",
      "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): ElectraEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-23): 24 x ElectraLayer(\n",
      "            (attention): ElectraAttention(\n",
      "              (self): ElectraSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): ElectraSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): ElectraIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): ElectraOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2025-03-09 02:22:20,946 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:22:20,946 Corpus: \"Corpus: 2000 train + 500 dev + 500 test sentences\"\n",
      "2025-03-09 02:22:20,946 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:22:20,947 Parameters:\n",
      "2025-03-09 02:22:20,947  - learning_rate: \"0.000005\"\n",
      "2025-03-09 02:22:20,948  - mini_batch_size: \"4\"\n",
      "2025-03-09 02:22:20,948  - patience: \"3\"\n",
      "2025-03-09 02:22:20,948  - anneal_factor: \"0.5\"\n",
      "2025-03-09 02:22:20,949  - max_epochs: \"10\"\n",
      "2025-03-09 02:22:20,949  - shuffle: \"True\"\n",
      "2025-03-09 02:22:20,950  - train_with_dev: \"False\"\n",
      "2025-03-09 02:22:20,950  - batch_growth_annealing: \"False\"\n",
      "2025-03-09 02:22:20,950 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:22:20,951 Model training base path: \"logs/PDSC_V2/GELECTRA/G29B/3K/k2\"\n",
      "2025-03-09 02:22:20,951 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:22:20,953 Device: cuda:0\n",
      "2025-03-09 02:22:20,953 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:22:20,953 Embeddings storage mode: none\n",
      "2025-03-09 02:22:20,954 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:22:28,157 epoch 1 - iter 50/500 - loss 0.35238337 - samples/sec: 28.25 - lr: 0.000001\n",
      "2025-03-09 02:22:36,100 epoch 1 - iter 100/500 - loss 0.26521352 - samples/sec: 26.47 - lr: 0.000001\n",
      "2025-03-09 02:22:43,697 epoch 1 - iter 150/500 - loss 0.18514196 - samples/sec: 27.58 - lr: 0.000002\n",
      "2025-03-09 02:22:51,647 epoch 1 - iter 200/500 - loss 0.13958882 - samples/sec: 27.16 - lr: 0.000002\n",
      "2025-03-09 02:22:58,786 epoch 1 - iter 250/500 - loss 0.11194477 - samples/sec: 29.43 - lr: 0.000003\n",
      "2025-03-09 02:23:06,505 epoch 1 - iter 300/500 - loss 0.16280479 - samples/sec: 27.12 - lr: 0.000003\n",
      "2025-03-09 02:23:14,210 epoch 1 - iter 350/500 - loss 0.13961708 - samples/sec: 27.22 - lr: 0.000003\n",
      "2025-03-09 02:23:21,539 epoch 1 - iter 400/500 - loss 0.12219650 - samples/sec: 28.62 - lr: 0.000004\n",
      "2025-03-09 02:23:29,717 epoch 1 - iter 450/500 - loss 0.10863917 - samples/sec: 25.57 - lr: 0.000005\n",
      "2025-03-09 02:23:37,038 epoch 1 - iter 500/500 - loss 0.09783643 - samples/sec: 28.76 - lr: 0.000005\n",
      "2025-03-09 02:23:37,282 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:23:37,282 EPOCH 1 done: loss 0.0978 - lr 0.000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 22.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:23:42,805 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:23:42,812 DEV : loss 1.1682065725326538 - f1-score (micro avg)  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:23:43,074 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:23:48,791 saving best model\n",
      "2025-03-09 02:23:55,621 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:24:02,771 epoch 2 - iter 50/500 - loss 0.29755195 - samples/sec: 28.39 - lr: 0.000005\n",
      "2025-03-09 02:24:10,750 epoch 2 - iter 100/500 - loss 0.24379061 - samples/sec: 26.23 - lr: 0.000005\n",
      "2025-03-09 02:24:18,218 epoch 2 - iter 150/500 - loss 0.22518392 - samples/sec: 28.07 - lr: 0.000005\n",
      "2025-03-09 02:24:25,614 epoch 2 - iter 200/500 - loss 0.21525708 - samples/sec: 28.40 - lr: 0.000005\n",
      "2025-03-09 02:24:32,998 epoch 2 - iter 250/500 - loss 0.20673071 - samples/sec: 28.45 - lr: 0.000005\n",
      "2025-03-09 02:24:40,848 epoch 2 - iter 300/500 - loss 0.20698943 - samples/sec: 26.68 - lr: 0.000005\n",
      "2025-03-09 02:24:48,564 epoch 2 - iter 350/500 - loss 0.20291576 - samples/sec: 27.14 - lr: 0.000005\n",
      "2025-03-09 02:24:56,790 epoch 2 - iter 400/500 - loss 0.19966468 - samples/sec: 25.41 - lr: 0.000005\n",
      "2025-03-09 02:25:04,379 epoch 2 - iter 450/500 - loss 0.19453707 - samples/sec: 27.60 - lr: 0.000005\n",
      "2025-03-09 02:25:11,705 epoch 2 - iter 500/500 - loss 0.18844682 - samples/sec: 28.66 - lr: 0.000004\n",
      "2025-03-09 02:25:11,951 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:25:11,951 EPOCH 2 done: loss 0.1884 - lr 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 22.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:25:17,527 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:25:17,535 DEV : loss 0.16280719637870789 - f1-score (micro avg)  0.716\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:25:18,082 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:25:23,279 saving best model\n",
      "2025-03-09 02:25:28,227 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:25:35,532 epoch 3 - iter 50/500 - loss 0.11662549 - samples/sec: 27.81 - lr: 0.000004\n",
      "2025-03-09 02:25:42,956 epoch 3 - iter 100/500 - loss 0.11810268 - samples/sec: 28.25 - lr: 0.000004\n",
      "2025-03-09 02:25:50,547 epoch 3 - iter 150/500 - loss 0.11373375 - samples/sec: 27.59 - lr: 0.000004\n",
      "2025-03-09 02:25:58,200 epoch 3 - iter 200/500 - loss 0.11667737 - samples/sec: 27.36 - lr: 0.000004\n",
      "2025-03-09 02:26:06,084 epoch 3 - iter 250/500 - loss 0.11218897 - samples/sec: 26.55 - lr: 0.000004\n",
      "2025-03-09 02:26:14,257 epoch 3 - iter 300/500 - loss 0.10798135 - samples/sec: 25.58 - lr: 0.000004\n",
      "2025-03-09 02:26:21,813 epoch 3 - iter 350/500 - loss 0.10695509 - samples/sec: 27.77 - lr: 0.000004\n",
      "2025-03-09 02:26:29,273 epoch 3 - iter 400/500 - loss 0.10554906 - samples/sec: 28.15 - lr: 0.000004\n",
      "2025-03-09 02:26:36,763 epoch 3 - iter 450/500 - loss 0.10604303 - samples/sec: 28.00 - lr: 0.000004\n",
      "2025-03-09 02:26:44,739 epoch 3 - iter 500/500 - loss 0.10540420 - samples/sec: 26.65 - lr: 0.000004\n",
      "2025-03-09 02:26:44,984 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:26:44,985 EPOCH 3 done: loss 0.1054 - lr 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 22.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:26:50,600 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:26:50,608 DEV : loss 0.1445467472076416 - f1-score (micro avg)  0.834\n",
      "2025-03-09 02:26:51,187 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:26:56,323 saving best model\n",
      "2025-03-09 02:27:01,183 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:27:08,479 epoch 4 - iter 50/500 - loss 0.05262766 - samples/sec: 27.83 - lr: 0.000004\n",
      "2025-03-09 02:27:16,155 epoch 4 - iter 100/500 - loss 0.05277209 - samples/sec: 27.85 - lr: 0.000004\n",
      "2025-03-09 02:27:23,745 epoch 4 - iter 150/500 - loss 0.04997096 - samples/sec: 27.64 - lr: 0.000004\n",
      "2025-03-09 02:27:31,131 epoch 4 - iter 200/500 - loss 0.05501050 - samples/sec: 28.43 - lr: 0.000004\n",
      "2025-03-09 02:27:38,587 epoch 4 - iter 250/500 - loss 0.06462547 - samples/sec: 28.11 - lr: 0.000004\n",
      "2025-03-09 02:27:46,035 epoch 4 - iter 300/500 - loss 0.06255679 - samples/sec: 28.18 - lr: 0.000004\n",
      "2025-03-09 02:27:53,438 epoch 4 - iter 350/500 - loss 0.06418159 - samples/sec: 28.51 - lr: 0.000004\n",
      "2025-03-09 02:28:00,871 epoch 4 - iter 400/500 - loss 0.06596967 - samples/sec: 28.26 - lr: 0.000003\n",
      "2025-03-09 02:28:09,328 epoch 4 - iter 450/500 - loss 0.06509953 - samples/sec: 24.71 - lr: 0.000003\n",
      "2025-03-09 02:28:16,943 epoch 4 - iter 500/500 - loss 0.06458419 - samples/sec: 27.51 - lr: 0.000003\n",
      "2025-03-09 02:28:17,189 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:28:17,189 EPOCH 4 done: loss 0.0646 - lr 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 22.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:28:22,732 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:28:22,739 DEV : loss 0.17341069877147675 - f1-score (micro avg)  0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:28:23,003 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:28:27,912 saving best model\n",
      "2025-03-09 02:28:33,252 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:28:40,803 epoch 5 - iter 50/500 - loss 0.04325542 - samples/sec: 26.87 - lr: 0.000003\n",
      "2025-03-09 02:28:48,584 epoch 5 - iter 100/500 - loss 0.03133554 - samples/sec: 26.90 - lr: 0.000003\n",
      "2025-03-09 02:28:56,184 epoch 5 - iter 150/500 - loss 0.03336327 - samples/sec: 27.58 - lr: 0.000003\n",
      "2025-03-09 02:29:03,706 epoch 5 - iter 200/500 - loss 0.03486111 - samples/sec: 27.89 - lr: 0.000003\n",
      "2025-03-09 02:29:11,577 epoch 5 - iter 250/500 - loss 0.03647746 - samples/sec: 26.60 - lr: 0.000003\n",
      "2025-03-09 02:29:19,096 epoch 5 - iter 300/500 - loss 0.03506222 - samples/sec: 27.89 - lr: 0.000003\n",
      "2025-03-09 02:29:27,155 epoch 5 - iter 350/500 - loss 0.03372428 - samples/sec: 25.95 - lr: 0.000003\n",
      "2025-03-09 02:29:35,057 epoch 5 - iter 400/500 - loss 0.03202661 - samples/sec: 26.48 - lr: 0.000003\n",
      "2025-03-09 02:29:42,623 epoch 5 - iter 450/500 - loss 0.03214384 - samples/sec: 27.72 - lr: 0.000003\n",
      "2025-03-09 02:29:50,263 epoch 5 - iter 500/500 - loss 0.03207587 - samples/sec: 27.42 - lr: 0.000003\n",
      "2025-03-09 02:29:50,511 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:29:50,511 EPOCH 5 done: loss 0.0321 - lr 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 22.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:29:56,034 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:29:56,041 DEV : loss 0.23496483266353607 - f1-score (micro avg)  0.844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:29:56,304 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:30:01,130 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:30:08,472 epoch 6 - iter 50/500 - loss 0.03282336 - samples/sec: 27.65 - lr: 0.000003\n",
      "2025-03-09 02:30:16,406 epoch 6 - iter 100/500 - loss 0.02110225 - samples/sec: 26.39 - lr: 0.000003\n",
      "2025-03-09 02:30:24,209 epoch 6 - iter 150/500 - loss 0.01633555 - samples/sec: 26.84 - lr: 0.000003\n",
      "2025-03-09 02:30:32,034 epoch 6 - iter 200/500 - loss 0.01972059 - samples/sec: 26.76 - lr: 0.000003\n",
      "2025-03-09 02:30:39,937 epoch 6 - iter 250/500 - loss 0.01845259 - samples/sec: 26.49 - lr: 0.000003\n",
      "2025-03-09 02:30:47,107 epoch 6 - iter 300/500 - loss 0.01787693 - samples/sec: 29.31 - lr: 0.000002\n",
      "2025-03-09 02:30:54,948 epoch 6 - iter 350/500 - loss 0.01795150 - samples/sec: 26.71 - lr: 0.000002\n",
      "2025-03-09 02:31:03,043 epoch 6 - iter 400/500 - loss 0.01962907 - samples/sec: 25.84 - lr: 0.000002\n",
      "2025-03-09 02:31:10,525 epoch 6 - iter 450/500 - loss 0.02206191 - samples/sec: 28.03 - lr: 0.000002\n",
      "2025-03-09 02:31:18,062 epoch 6 - iter 500/500 - loss 0.02266517 - samples/sec: 27.81 - lr: 0.000002\n",
      "2025-03-09 02:31:18,315 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:31:18,315 EPOCH 6 done: loss 0.0227 - lr 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 22.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:31:23,848 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:31:23,857 DEV : loss 0.21690240502357483 - f1-score (micro avg)  0.846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:31:24,406 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:31:29,337 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:31:36,697 epoch 7 - iter 50/500 - loss 0.00211856 - samples/sec: 27.58 - lr: 0.000002\n",
      "2025-03-09 02:31:44,251 epoch 7 - iter 100/500 - loss 0.00854347 - samples/sec: 27.78 - lr: 0.000002\n",
      "2025-03-09 02:31:51,488 epoch 7 - iter 150/500 - loss 0.01382980 - samples/sec: 29.03 - lr: 0.000002\n",
      "2025-03-09 02:31:58,677 epoch 7 - iter 200/500 - loss 0.01436456 - samples/sec: 29.25 - lr: 0.000002\n",
      "2025-03-09 02:32:06,361 epoch 7 - iter 250/500 - loss 0.01407075 - samples/sec: 27.27 - lr: 0.000002\n",
      "2025-03-09 02:32:14,472 epoch 7 - iter 300/500 - loss 0.01433560 - samples/sec: 25.77 - lr: 0.000002\n",
      "2025-03-09 02:32:22,001 epoch 7 - iter 350/500 - loss 0.01249979 - samples/sec: 27.86 - lr: 0.000002\n",
      "2025-03-09 02:32:29,696 epoch 7 - iter 400/500 - loss 0.01425931 - samples/sec: 27.29 - lr: 0.000002\n",
      "2025-03-09 02:32:37,195 epoch 7 - iter 450/500 - loss 0.01397265 - samples/sec: 27.97 - lr: 0.000002\n",
      "2025-03-09 02:32:44,904 epoch 7 - iter 500/500 - loss 0.01315772 - samples/sec: 27.19 - lr: 0.000002\n",
      "2025-03-09 02:32:45,153 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:32:45,153 EPOCH 7 done: loss 0.0132 - lr 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 22.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:32:50,710 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:32:50,718 DEV : loss 0.24917937815189362 - f1-score (micro avg)  0.852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:32:51,315 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:32:56,241 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:33:03,492 epoch 8 - iter 50/500 - loss 0.00407805 - samples/sec: 28.00 - lr: 0.000002\n",
      "2025-03-09 02:33:10,741 epoch 8 - iter 100/500 - loss 0.00651307 - samples/sec: 28.97 - lr: 0.000002\n",
      "2025-03-09 02:33:18,674 epoch 8 - iter 150/500 - loss 0.00531536 - samples/sec: 26.39 - lr: 0.000002\n",
      "2025-03-09 02:33:26,462 epoch 8 - iter 200/500 - loss 0.00657285 - samples/sec: 26.91 - lr: 0.000001\n",
      "2025-03-09 02:33:34,156 epoch 8 - iter 250/500 - loss 0.00578564 - samples/sec: 27.24 - lr: 0.000001\n",
      "2025-03-09 02:33:41,824 epoch 8 - iter 300/500 - loss 0.00491030 - samples/sec: 27.32 - lr: 0.000001\n",
      "2025-03-09 02:33:49,548 epoch 8 - iter 350/500 - loss 0.00474843 - samples/sec: 27.12 - lr: 0.000001\n",
      "2025-03-09 02:33:57,398 epoch 8 - iter 400/500 - loss 0.00536032 - samples/sec: 26.74 - lr: 0.000001\n",
      "2025-03-09 02:34:05,060 epoch 8 - iter 450/500 - loss 0.00525537 - samples/sec: 27.35 - lr: 0.000001\n",
      "2025-03-09 02:34:12,701 epoch 8 - iter 500/500 - loss 0.00613077 - samples/sec: 27.44 - lr: 0.000001\n",
      "2025-03-09 02:34:12,948 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:34:12,949 EPOCH 8 done: loss 0.0061 - lr 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 22.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:34:18,484 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:34:18,492 DEV : loss 0.28951847553253174 - f1-score (micro avg)  0.852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:34:19,077 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:34:24,022 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:34:31,614 epoch 9 - iter 50/500 - loss 0.01436708 - samples/sec: 26.73 - lr: 0.000001\n",
      "2025-03-09 02:34:39,586 epoch 9 - iter 100/500 - loss 0.00728044 - samples/sec: 26.25 - lr: 0.000001\n",
      "2025-03-09 02:34:46,942 epoch 9 - iter 150/500 - loss 0.00506873 - samples/sec: 28.53 - lr: 0.000001\n",
      "2025-03-09 02:34:54,459 epoch 9 - iter 200/500 - loss 0.00524028 - samples/sec: 27.88 - lr: 0.000001\n",
      "2025-03-09 02:35:02,129 epoch 9 - iter 250/500 - loss 0.00452530 - samples/sec: 27.32 - lr: 0.000001\n",
      "2025-03-09 02:35:09,352 epoch 9 - iter 300/500 - loss 0.00491091 - samples/sec: 29.08 - lr: 0.000001\n",
      "2025-03-09 02:35:16,587 epoch 9 - iter 350/500 - loss 0.00503962 - samples/sec: 29.02 - lr: 0.000001\n",
      "2025-03-09 02:35:24,340 epoch 9 - iter 400/500 - loss 0.00551101 - samples/sec: 27.00 - lr: 0.000001\n",
      "2025-03-09 02:35:32,098 epoch 9 - iter 450/500 - loss 0.00490705 - samples/sec: 26.99 - lr: 0.000001\n",
      "2025-03-09 02:35:39,860 epoch 9 - iter 500/500 - loss 0.00488922 - samples/sec: 26.99 - lr: 0.000001\n",
      "2025-03-09 02:35:40,106 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:35:40,106 EPOCH 9 done: loss 0.0049 - lr 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 21.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:35:45,941 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:35:45,949 DEV : loss 0.2851616442203522 - f1-score (micro avg)  0.856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:35:46,209 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:35:51,225 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:35:58,180 epoch 10 - iter 50/500 - loss 0.00117513 - samples/sec: 29.19 - lr: 0.000001\n",
      "2025-03-09 02:36:06,320 epoch 10 - iter 100/500 - loss 0.00063555 - samples/sec: 25.80 - lr: 0.000000\n",
      "2025-03-09 02:36:13,909 epoch 10 - iter 150/500 - loss 0.00048373 - samples/sec: 27.63 - lr: 0.000000\n",
      "2025-03-09 02:36:21,564 epoch 10 - iter 200/500 - loss 0.00054199 - samples/sec: 27.38 - lr: 0.000000\n",
      "2025-03-09 02:36:29,927 epoch 10 - iter 250/500 - loss 0.00051051 - samples/sec: 24.95 - lr: 0.000000\n",
      "2025-03-09 02:36:37,277 epoch 10 - iter 300/500 - loss 0.00054026 - samples/sec: 28.54 - lr: 0.000000\n",
      "2025-03-09 02:36:44,581 epoch 10 - iter 350/500 - loss 0.00176500 - samples/sec: 28.74 - lr: 0.000000\n",
      "2025-03-09 02:36:52,915 epoch 10 - iter 400/500 - loss 0.00162352 - samples/sec: 25.15 - lr: 0.000000\n",
      "2025-03-09 02:37:00,238 epoch 10 - iter 450/500 - loss 0.00147641 - samples/sec: 28.65 - lr: 0.000000\n",
      "2025-03-09 02:37:08,064 epoch 10 - iter 500/500 - loss 0.00156846 - samples/sec: 26.76 - lr: 0.000000\n",
      "2025-03-09 02:37:08,313 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:37:08,314 EPOCH 10 done: loss 0.0016 - lr 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 22.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:37:13,844 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:37:13,852 DEV : loss 0.29346781969070435 - f1-score (micro avg)  0.854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:37:14,116 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:37:19,011 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:37:19,013 loading file logs/PDSC_V2/GELECTRA/G29B/3K/k2/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 23.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:37:37,071 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:37:37,078 0.848\t0.848\t0.848\t0.848\n",
      "2025-03-09 02:37:37,079 \n",
      "Results:\n",
      "- F-score (micro) 0.848\n",
      "- F-score (macro) 0.8479\n",
      "- Accuracy 0.848\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        ORIG     0.8346    0.8680    0.8510       250\n",
      "       PSEUD     0.8625    0.8280    0.8449       250\n",
      "\n",
      "    accuracy                         0.8480       500\n",
      "   macro avg     0.8486    0.8480    0.8479       500\n",
      "weighted avg     0.8486    0.8480    0.8479       500\n",
      "\n",
      "2025-03-09 02:37:37,079 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:37:37,157 Reading data from tmp_data_dir\n",
      "2025-03-09 02:37:37,158 Train: tmp_data_dir/train.csv\n",
      "2025-03-09 02:37:37,158 Dev: tmp_data_dir/dev.csv\n",
      "2025-03-09 02:37:37,158 Test: tmp_data_dir/test.csv\n",
      "2025-03-09 02:37:37,171 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:01, 1458.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:37:38,544 Dictionary created for label 'label' with 3 values: ORIG (seen 1000 times), PSEUD (seen 1000 times)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/s81481/pseugc/lib/python3.9/site-packages/transformers/modeling_utils.py:349: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:37:44,860 tensorboard logging path is logs/PDSC_V2/GELECTRA/G29B/3K/k3\n",
      "2025-03-09 02:37:44,867 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:37:44,868 Model: \"TextClassifier(\n",
      "  (decoder): Linear(in_features=1024, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (document_embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): ElectraModel(\n",
      "      (embeddings): ElectraEmbeddings(\n",
      "        (word_embeddings): Embedding(31102, 1024, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 1024)\n",
      "        (token_type_embeddings): Embedding(2, 1024)\n",
      "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): ElectraEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-23): 24 x ElectraLayer(\n",
      "            (attention): ElectraAttention(\n",
      "              (self): ElectraSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): ElectraSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): ElectraIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): ElectraOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2025-03-09 02:37:44,869 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:37:44,869 Corpus: \"Corpus: 2000 train + 500 dev + 500 test sentences\"\n",
      "2025-03-09 02:37:44,869 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:37:44,870 Parameters:\n",
      "2025-03-09 02:37:44,870  - learning_rate: \"0.000005\"\n",
      "2025-03-09 02:37:44,870  - mini_batch_size: \"4\"\n",
      "2025-03-09 02:37:44,871  - patience: \"3\"\n",
      "2025-03-09 02:37:44,871  - anneal_factor: \"0.5\"\n",
      "2025-03-09 02:37:44,871  - max_epochs: \"10\"\n",
      "2025-03-09 02:37:44,872  - shuffle: \"True\"\n",
      "2025-03-09 02:37:44,872  - train_with_dev: \"False\"\n",
      "2025-03-09 02:37:44,872  - batch_growth_annealing: \"False\"\n",
      "2025-03-09 02:37:44,873 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:37:44,873 Model training base path: \"logs/PDSC_V2/GELECTRA/G29B/3K/k3\"\n",
      "2025-03-09 02:37:44,873 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:37:44,873 Device: cuda:0\n",
      "2025-03-09 02:37:44,874 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:37:44,874 Embeddings storage mode: none\n",
      "2025-03-09 02:37:44,874 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:37:52,225 epoch 1 - iter 50/500 - loss 0.16309536 - samples/sec: 27.65 - lr: 0.000001\n",
      "2025-03-09 02:38:00,119 epoch 1 - iter 100/500 - loss 0.11569469 - samples/sec: 26.63 - lr: 0.000001\n",
      "2025-03-09 02:38:07,982 epoch 1 - iter 150/500 - loss 0.08092519 - samples/sec: 26.62 - lr: 0.000002\n",
      "2025-03-09 02:38:16,111 epoch 1 - iter 200/500 - loss 0.06150419 - samples/sec: 25.73 - lr: 0.000002\n",
      "2025-03-09 02:38:23,585 epoch 1 - iter 250/500 - loss 0.04948382 - samples/sec: 28.06 - lr: 0.000003\n",
      "2025-03-09 02:38:31,171 epoch 1 - iter 300/500 - loss 0.11988932 - samples/sec: 27.63 - lr: 0.000003\n",
      "2025-03-09 02:38:39,487 epoch 1 - iter 350/500 - loss 0.10282937 - samples/sec: 25.12 - lr: 0.000003\n",
      "2025-03-09 02:38:46,700 epoch 1 - iter 400/500 - loss 0.09000216 - samples/sec: 29.11 - lr: 0.000004\n",
      "2025-03-09 02:38:54,390 epoch 1 - iter 450/500 - loss 0.08001802 - samples/sec: 27.26 - lr: 0.000005\n",
      "2025-03-09 02:39:01,795 epoch 1 - iter 500/500 - loss 0.07202679 - samples/sec: 28.33 - lr: 0.000005\n",
      "2025-03-09 02:39:02,041 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:39:02,041 EPOCH 1 done: loss 0.0720 - lr 0.000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 22.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:39:07,546 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:39:07,554 DEV : loss 1.1799248456954956 - f1-score (micro avg)  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:39:08,094 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:39:13,213 saving best model\n",
      "2025-03-09 02:39:20,040 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:39:27,585 epoch 2 - iter 50/500 - loss 0.27911917 - samples/sec: 26.89 - lr: 0.000005\n",
      "2025-03-09 02:39:35,274 epoch 2 - iter 100/500 - loss 0.24009130 - samples/sec: 27.26 - lr: 0.000005\n",
      "2025-03-09 02:39:43,210 epoch 2 - iter 150/500 - loss 0.22666732 - samples/sec: 26.35 - lr: 0.000005\n",
      "2025-03-09 02:39:50,597 epoch 2 - iter 200/500 - loss 0.21635227 - samples/sec: 28.43 - lr: 0.000005\n",
      "2025-03-09 02:39:58,516 epoch 2 - iter 250/500 - loss 0.21134198 - samples/sec: 26.43 - lr: 0.000005\n",
      "2025-03-09 02:40:06,521 epoch 2 - iter 300/500 - loss 0.20629209 - samples/sec: 26.12 - lr: 0.000005\n",
      "2025-03-09 02:40:14,185 epoch 2 - iter 350/500 - loss 0.20162346 - samples/sec: 27.33 - lr: 0.000005\n",
      "2025-03-09 02:40:21,338 epoch 2 - iter 400/500 - loss 0.19967882 - samples/sec: 29.38 - lr: 0.000005\n",
      "2025-03-09 02:40:28,852 epoch 2 - iter 450/500 - loss 0.19755187 - samples/sec: 27.91 - lr: 0.000005\n",
      "2025-03-09 02:40:37,359 epoch 2 - iter 500/500 - loss 0.19552767 - samples/sec: 24.54 - lr: 0.000004\n",
      "2025-03-09 02:40:37,607 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:40:37,607 EPOCH 2 done: loss 0.1955 - lr 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 22.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:40:43,106 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:40:43,113 DEV : loss 0.1740008145570755 - f1-score (micro avg)  0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:40:43,376 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:40:48,248 saving best model\n",
      "2025-03-09 02:40:53,111 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:41:00,281 epoch 3 - iter 50/500 - loss 0.18399057 - samples/sec: 28.33 - lr: 0.000004\n",
      "2025-03-09 02:41:07,878 epoch 3 - iter 100/500 - loss 0.18161125 - samples/sec: 27.58 - lr: 0.000004\n",
      "2025-03-09 02:41:15,695 epoch 3 - iter 150/500 - loss 0.18087672 - samples/sec: 26.77 - lr: 0.000004\n",
      "2025-03-09 02:41:23,371 epoch 3 - iter 200/500 - loss 0.18029465 - samples/sec: 27.31 - lr: 0.000004\n",
      "2025-03-09 02:41:31,303 epoch 3 - iter 250/500 - loss 0.17971759 - samples/sec: 26.40 - lr: 0.000004\n",
      "2025-03-09 02:41:38,984 epoch 3 - iter 300/500 - loss 0.17966611 - samples/sec: 27.27 - lr: 0.000004\n",
      "2025-03-09 02:41:46,848 epoch 3 - iter 350/500 - loss 0.17925026 - samples/sec: 26.60 - lr: 0.000004\n",
      "2025-03-09 02:41:54,862 epoch 3 - iter 400/500 - loss 0.17949082 - samples/sec: 26.11 - lr: 0.000004\n",
      "2025-03-09 02:42:02,488 epoch 3 - iter 450/500 - loss 0.17914521 - samples/sec: 27.50 - lr: 0.000004\n",
      "2025-03-09 02:42:10,658 epoch 3 - iter 500/500 - loss 0.17857772 - samples/sec: 25.57 - lr: 0.000004\n",
      "2025-03-09 02:42:10,905 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:42:10,905 EPOCH 3 done: loss 0.1786 - lr 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 22.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:42:16,396 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:42:16,403 DEV : loss 0.1745978593826294 - f1-score (micro avg)  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:42:16,669 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:42:21,547 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:42:29,212 epoch 4 - iter 50/500 - loss 0.17951241 - samples/sec: 26.47 - lr: 0.000004\n",
      "2025-03-09 02:42:36,523 epoch 4 - iter 100/500 - loss 0.17799640 - samples/sec: 28.73 - lr: 0.000004\n",
      "2025-03-09 02:42:44,193 epoch 4 - iter 150/500 - loss 0.17853765 - samples/sec: 27.33 - lr: 0.000004\n",
      "2025-03-09 02:42:52,221 epoch 4 - iter 200/500 - loss 0.17858554 - samples/sec: 26.07 - lr: 0.000004\n",
      "2025-03-09 02:43:00,463 epoch 4 - iter 250/500 - loss 0.17815321 - samples/sec: 26.34 - lr: 0.000004\n",
      "2025-03-09 02:43:08,400 epoch 4 - iter 300/500 - loss 0.17766944 - samples/sec: 26.38 - lr: 0.000004\n",
      "2025-03-09 02:43:15,991 epoch 4 - iter 350/500 - loss 0.17784225 - samples/sec: 27.63 - lr: 0.000004\n",
      "2025-03-09 02:43:23,597 epoch 4 - iter 400/500 - loss 0.17758685 - samples/sec: 27.56 - lr: 0.000003\n",
      "2025-03-09 02:43:31,545 epoch 4 - iter 450/500 - loss 0.17760270 - samples/sec: 26.33 - lr: 0.000003\n",
      "2025-03-09 02:43:38,913 epoch 4 - iter 500/500 - loss 0.17764576 - samples/sec: 28.49 - lr: 0.000003\n",
      "2025-03-09 02:43:39,161 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:43:39,162 EPOCH 4 done: loss 0.1776 - lr 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 22.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:43:44,643 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:43:44,650 DEV : loss 0.1736781746149063 - f1-score (micro avg)  0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:43:44,914 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:43:49,821 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:43:57,361 epoch 5 - iter 50/500 - loss 0.17597067 - samples/sec: 26.92 - lr: 0.000003\n",
      "2025-03-09 02:44:05,274 epoch 5 - iter 100/500 - loss 0.17521727 - samples/sec: 27.53 - lr: 0.000003\n",
      "2025-03-09 02:44:12,674 epoch 5 - iter 150/500 - loss 0.17418397 - samples/sec: 28.34 - lr: 0.000003\n",
      "2025-03-09 02:44:20,460 epoch 5 - iter 200/500 - loss 0.17493666 - samples/sec: 26.89 - lr: 0.000003\n",
      "2025-03-09 02:44:28,175 epoch 5 - iter 250/500 - loss 0.17529862 - samples/sec: 27.19 - lr: 0.000003\n",
      "2025-03-09 02:44:35,916 epoch 5 - iter 300/500 - loss 0.17490072 - samples/sec: 27.07 - lr: 0.000003\n",
      "2025-03-09 02:44:44,080 epoch 5 - iter 350/500 - loss 0.17499036 - samples/sec: 25.62 - lr: 0.000003\n",
      "2025-03-09 02:44:51,704 epoch 5 - iter 400/500 - loss 0.17489844 - samples/sec: 27.53 - lr: 0.000003\n",
      "2025-03-09 02:44:59,463 epoch 5 - iter 450/500 - loss 0.17531738 - samples/sec: 27.00 - lr: 0.000003\n",
      "2025-03-09 02:45:06,811 epoch 5 - iter 500/500 - loss 0.17518821 - samples/sec: 28.57 - lr: 0.000003\n",
      "2025-03-09 02:45:07,061 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:45:07,062 EPOCH 5 done: loss 0.1752 - lr 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 22.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:45:12,540 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:45:12,547 DEV : loss 0.17425857484340668 - f1-score (micro avg)  0.496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:45:13,093 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:45:17,985 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:45:25,724 epoch 6 - iter 50/500 - loss 0.17564812 - samples/sec: 26.24 - lr: 0.000003\n",
      "2025-03-09 02:45:33,182 epoch 6 - iter 100/500 - loss 0.17636477 - samples/sec: 28.13 - lr: 0.000003\n",
      "2025-03-09 02:45:40,647 epoch 6 - iter 150/500 - loss 0.17694867 - samples/sec: 28.09 - lr: 0.000003\n",
      "2025-03-09 02:45:48,319 epoch 6 - iter 200/500 - loss 0.17697793 - samples/sec: 27.30 - lr: 0.000003\n",
      "2025-03-09 02:45:55,806 epoch 6 - iter 250/500 - loss 0.17646609 - samples/sec: 28.00 - lr: 0.000003\n",
      "2025-03-09 02:46:03,838 epoch 6 - iter 300/500 - loss 0.17570505 - samples/sec: 26.08 - lr: 0.000002\n",
      "2025-03-09 02:46:11,431 epoch 6 - iter 350/500 - loss 0.17614616 - samples/sec: 27.60 - lr: 0.000002\n",
      "2025-03-09 02:46:19,158 epoch 6 - iter 400/500 - loss 0.17655845 - samples/sec: 27.13 - lr: 0.000002\n",
      "2025-03-09 02:46:27,048 epoch 6 - iter 450/500 - loss 0.17678705 - samples/sec: 26.52 - lr: 0.000002\n",
      "2025-03-09 02:46:35,078 epoch 6 - iter 500/500 - loss 0.17627424 - samples/sec: 26.04 - lr: 0.000002\n",
      "2025-03-09 02:46:35,324 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:46:35,324 EPOCH 6 done: loss 0.1763 - lr 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 22.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:46:40,800 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:46:40,808 DEV : loss 0.17453239858150482 - f1-score (micro avg)  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:46:41,387 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:46:46,307 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:46:54,229 epoch 7 - iter 50/500 - loss 0.17531666 - samples/sec: 25.59 - lr: 0.000002\n",
      "2025-03-09 02:47:02,038 epoch 7 - iter 100/500 - loss 0.17428954 - samples/sec: 26.83 - lr: 0.000002\n",
      "2025-03-09 02:47:09,649 epoch 7 - iter 150/500 - loss 0.17414199 - samples/sec: 27.54 - lr: 0.000002\n",
      "2025-03-09 02:47:16,851 epoch 7 - iter 200/500 - loss 0.17428005 - samples/sec: 29.16 - lr: 0.000002\n",
      "2025-03-09 02:47:24,208 epoch 7 - iter 250/500 - loss 0.17411689 - samples/sec: 28.53 - lr: 0.000002\n",
      "2025-03-09 02:47:32,697 epoch 7 - iter 300/500 - loss 0.17506515 - samples/sec: 24.59 - lr: 0.000002\n",
      "2025-03-09 02:47:40,620 epoch 7 - iter 350/500 - loss 0.17573018 - samples/sec: 26.42 - lr: 0.000002\n",
      "2025-03-09 02:47:48,247 epoch 7 - iter 400/500 - loss 0.17564821 - samples/sec: 27.45 - lr: 0.000002\n",
      "2025-03-09 02:47:56,011 epoch 7 - iter 450/500 - loss 0.17576181 - samples/sec: 26.99 - lr: 0.000002\n",
      "2025-03-09 02:48:03,495 epoch 7 - iter 500/500 - loss 0.17578634 - samples/sec: 28.02 - lr: 0.000002\n",
      "2025-03-09 02:48:03,742 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:48:03,743 EPOCH 7 done: loss 0.1758 - lr 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 22.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:48:09,439 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:48:09,447 DEV : loss 0.1742907166481018 - f1-score (micro avg)  0.486\n",
      "2025-03-09 02:48:10,022 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:48:15,162 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:48:22,561 epoch 8 - iter 50/500 - loss 0.17800147 - samples/sec: 27.41 - lr: 0.000002\n",
      "2025-03-09 02:48:30,318 epoch 8 - iter 100/500 - loss 0.17736662 - samples/sec: 27.00 - lr: 0.000002\n",
      "2025-03-09 02:48:38,322 epoch 8 - iter 150/500 - loss 0.17609905 - samples/sec: 26.13 - lr: 0.000002\n",
      "2025-03-09 02:48:46,415 epoch 8 - iter 200/500 - loss 0.17743606 - samples/sec: 25.83 - lr: 0.000001\n",
      "2025-03-09 02:48:54,257 epoch 8 - iter 250/500 - loss 0.17694658 - samples/sec: 26.74 - lr: 0.000001\n",
      "2025-03-09 02:49:01,792 epoch 8 - iter 300/500 - loss 0.17650981 - samples/sec: 27.81 - lr: 0.000001\n",
      "2025-03-09 02:49:09,299 epoch 8 - iter 350/500 - loss 0.17624886 - samples/sec: 27.93 - lr: 0.000001\n",
      "2025-03-09 02:49:16,793 epoch 8 - iter 400/500 - loss 0.17514351 - samples/sec: 27.96 - lr: 0.000001\n",
      "2025-03-09 02:49:24,796 epoch 8 - iter 450/500 - loss 0.17455112 - samples/sec: 26.16 - lr: 0.000001\n",
      "2025-03-09 02:49:33,170 epoch 8 - iter 500/500 - loss 0.17467622 - samples/sec: 25.86 - lr: 0.000001\n",
      "2025-03-09 02:49:33,412 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:49:33,413 EPOCH 8 done: loss 0.1747 - lr 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 22.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:49:39,079 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:49:39,087 DEV : loss 0.18465004861354828 - f1-score (micro avg)  0.544\n",
      "2025-03-09 02:49:39,350 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:49:44,268 saving best model\n",
      "2025-03-09 02:49:49,462 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:49:56,451 epoch 9 - iter 50/500 - loss 0.16537085 - samples/sec: 29.04 - lr: 0.000001\n",
      "2025-03-09 02:50:04,085 epoch 9 - iter 100/500 - loss 0.16685047 - samples/sec: 27.44 - lr: 0.000001\n",
      "2025-03-09 02:50:11,824 epoch 9 - iter 150/500 - loss 0.16421926 - samples/sec: 27.08 - lr: 0.000001\n",
      "2025-03-09 02:50:19,769 epoch 9 - iter 200/500 - loss 0.16909809 - samples/sec: 26.32 - lr: 0.000001\n",
      "2025-03-09 02:50:27,147 epoch 9 - iter 250/500 - loss 0.16809498 - samples/sec: 28.45 - lr: 0.000001\n",
      "2025-03-09 02:50:35,017 epoch 9 - iter 300/500 - loss 0.16643884 - samples/sec: 26.73 - lr: 0.000001\n",
      "2025-03-09 02:50:42,550 epoch 9 - iter 350/500 - loss 0.16695217 - samples/sec: 27.83 - lr: 0.000001\n",
      "2025-03-09 02:50:50,440 epoch 9 - iter 400/500 - loss 0.16454645 - samples/sec: 26.53 - lr: 0.000001\n",
      "2025-03-09 02:50:58,247 epoch 9 - iter 450/500 - loss 0.16584872 - samples/sec: 26.82 - lr: 0.000001\n",
      "2025-03-09 02:51:06,353 epoch 9 - iter 500/500 - loss 0.16617414 - samples/sec: 25.89 - lr: 0.000001\n",
      "2025-03-09 02:51:06,599 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:51:06,600 EPOCH 9 done: loss 0.1662 - lr 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 22.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:51:12,390 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:51:12,398 DEV : loss 0.20700104534626007 - f1-score (micro avg)  0.574\n",
      "2025-03-09 02:51:12,657 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:51:17,647 saving best model\n",
      "2025-03-09 02:51:22,492 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:51:30,174 epoch 10 - iter 50/500 - loss 0.15511726 - samples/sec: 26.41 - lr: 0.000001\n",
      "2025-03-09 02:51:38,512 epoch 10 - iter 100/500 - loss 0.15514675 - samples/sec: 26.07 - lr: 0.000000\n",
      "2025-03-09 02:51:46,228 epoch 10 - iter 150/500 - loss 0.15115171 - samples/sec: 27.15 - lr: 0.000000\n",
      "2025-03-09 02:51:53,885 epoch 10 - iter 200/500 - loss 0.14952321 - samples/sec: 27.41 - lr: 0.000000\n",
      "2025-03-09 02:52:01,244 epoch 10 - iter 250/500 - loss 0.15005018 - samples/sec: 28.51 - lr: 0.000000\n",
      "2025-03-09 02:52:08,751 epoch 10 - iter 300/500 - loss 0.14980345 - samples/sec: 27.92 - lr: 0.000000\n",
      "2025-03-09 02:52:16,477 epoch 10 - iter 350/500 - loss 0.14836612 - samples/sec: 27.13 - lr: 0.000000\n",
      "2025-03-09 02:52:23,845 epoch 10 - iter 400/500 - loss 0.14648788 - samples/sec: 28.47 - lr: 0.000000\n",
      "2025-03-09 02:52:31,451 epoch 10 - iter 450/500 - loss 0.14828677 - samples/sec: 27.56 - lr: 0.000000\n",
      "2025-03-09 02:52:39,336 epoch 10 - iter 500/500 - loss 0.14722846 - samples/sec: 26.55 - lr: 0.000000\n",
      "2025-03-09 02:52:39,684 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:52:39,685 EPOCH 10 done: loss 0.1472 - lr 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 22.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:52:45,464 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:52:45,473 DEV : loss 0.2200390100479126 - f1-score (micro avg)  0.604\n",
      "2025-03-09 02:52:46,025 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:52:51,225 saving best model\n",
      "2025-03-09 02:52:56,085 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:52:56,088 loading file logs/PDSC_V2/GELECTRA/G29B/3K/k3/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 23.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:53:14,845 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:53:14,852 0.626\t0.626\t0.626\t0.626\n",
      "2025-03-09 02:53:14,852 \n",
      "Results:\n",
      "- F-score (micro) 0.626\n",
      "- F-score (macro) 0.62\n",
      "- Accuracy 0.626\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       PSEUD     0.6006    0.7520    0.6679       250\n",
      "        ORIG     0.6684    0.5000    0.5721       250\n",
      "\n",
      "    accuracy                         0.6260       500\n",
      "   macro avg     0.6345    0.6260    0.6200       500\n",
      "weighted avg     0.6345    0.6260    0.6200       500\n",
      "\n",
      "2025-03-09 02:53:14,853 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:53:14,930 Reading data from tmp_data_dir\n",
      "2025-03-09 02:53:14,930 Train: tmp_data_dir/train.csv\n",
      "2025-03-09 02:53:14,930 Dev: tmp_data_dir/dev.csv\n",
      "2025-03-09 02:53:14,931 Test: tmp_data_dir/test.csv\n",
      "2025-03-09 02:53:14,944 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:01, 1957.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:53:15,967 Dictionary created for label 'label' with 3 values: ORIG (seen 1000 times), PSEUD (seen 1000 times)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/s81481/pseugc/lib/python3.9/site-packages/transformers/modeling_utils.py:349: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:53:23,950 tensorboard logging path is logs/PDSC_V2/GELECTRA/G29B/3K/k4\n",
      "2025-03-09 02:53:24,402 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:53:24,404 Model: \"TextClassifier(\n",
      "  (decoder): Linear(in_features=1024, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (document_embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): ElectraModel(\n",
      "      (embeddings): ElectraEmbeddings(\n",
      "        (word_embeddings): Embedding(31102, 1024, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 1024)\n",
      "        (token_type_embeddings): Embedding(2, 1024)\n",
      "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): ElectraEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-23): 24 x ElectraLayer(\n",
      "            (attention): ElectraAttention(\n",
      "              (self): ElectraSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): ElectraSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): ElectraIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): ElectraOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2025-03-09 02:53:24,404 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:53:24,405 Corpus: \"Corpus: 2000 train + 500 dev + 500 test sentences\"\n",
      "2025-03-09 02:53:24,405 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:53:24,405 Parameters:\n",
      "2025-03-09 02:53:24,406  - learning_rate: \"0.000005\"\n",
      "2025-03-09 02:53:24,406  - mini_batch_size: \"4\"\n",
      "2025-03-09 02:53:24,406  - patience: \"3\"\n",
      "2025-03-09 02:53:24,406  - anneal_factor: \"0.5\"\n",
      "2025-03-09 02:53:24,407  - max_epochs: \"10\"\n",
      "2025-03-09 02:53:24,407  - shuffle: \"True\"\n",
      "2025-03-09 02:53:24,407  - train_with_dev: \"False\"\n",
      "2025-03-09 02:53:24,408  - batch_growth_annealing: \"False\"\n",
      "2025-03-09 02:53:24,408 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:53:24,408 Model training base path: \"logs/PDSC_V2/GELECTRA/G29B/3K/k4\"\n",
      "2025-03-09 02:53:24,408 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:53:24,409 Device: cuda:0\n",
      "2025-03-09 02:53:24,409 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:53:24,409 Embeddings storage mode: none\n",
      "2025-03-09 02:53:24,409 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:53:31,544 epoch 1 - iter 50/500 - loss 0.29561801 - samples/sec: 28.47 - lr: 0.000001\n",
      "2025-03-09 02:53:39,088 epoch 1 - iter 100/500 - loss 0.20989297 - samples/sec: 27.94 - lr: 0.000001\n",
      "2025-03-09 02:53:46,935 epoch 1 - iter 150/500 - loss 0.14543268 - samples/sec: 26.68 - lr: 0.000002\n",
      "2025-03-09 02:53:54,804 epoch 1 - iter 200/500 - loss 0.10983167 - samples/sec: 26.59 - lr: 0.000002\n",
      "2025-03-09 02:54:01,910 epoch 1 - iter 250/500 - loss 0.08820273 - samples/sec: 29.57 - lr: 0.000003\n",
      "2025-03-09 02:54:09,222 epoch 1 - iter 300/500 - loss 0.17495061 - samples/sec: 28.72 - lr: 0.000003\n",
      "2025-03-09 02:54:16,740 epoch 1 - iter 350/500 - loss 0.15013590 - samples/sec: 27.90 - lr: 0.000003\n",
      "2025-03-09 02:54:24,372 epoch 1 - iter 400/500 - loss 0.13140826 - samples/sec: 27.49 - lr: 0.000004\n",
      "2025-03-09 02:54:32,732 epoch 1 - iter 450/500 - loss 0.11683122 - samples/sec: 24.98 - lr: 0.000005\n",
      "2025-03-09 02:54:40,180 epoch 1 - iter 500/500 - loss 0.10516336 - samples/sec: 28.15 - lr: 0.000005\n",
      "2025-03-09 02:54:40,515 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:54:40,515 EPOCH 1 done: loss 0.1052 - lr 0.000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 21.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:54:46,228 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:54:46,235 DEV : loss 1.0993297100067139 - f1-score (micro avg)  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:54:46,503 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:54:52,104 saving best model\n",
      "2025-03-09 02:54:59,226 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:55:06,804 epoch 2 - iter 50/500 - loss 0.34014958 - samples/sec: 26.78 - lr: 0.000005\n",
      "2025-03-09 02:55:14,551 epoch 2 - iter 100/500 - loss 0.26411686 - samples/sec: 27.05 - lr: 0.000005\n",
      "2025-03-09 02:55:22,478 epoch 2 - iter 150/500 - loss 0.23605682 - samples/sec: 26.40 - lr: 0.000005\n",
      "2025-03-09 02:55:30,516 epoch 2 - iter 200/500 - loss 0.21925927 - samples/sec: 26.02 - lr: 0.000005\n",
      "2025-03-09 02:55:38,175 epoch 2 - iter 250/500 - loss 0.20856539 - samples/sec: 27.37 - lr: 0.000005\n",
      "2025-03-09 02:55:45,802 epoch 2 - iter 300/500 - loss 0.19826574 - samples/sec: 27.50 - lr: 0.000005\n",
      "2025-03-09 02:55:53,460 epoch 2 - iter 350/500 - loss 0.19106973 - samples/sec: 27.36 - lr: 0.000005\n",
      "2025-03-09 02:56:00,991 epoch 2 - iter 400/500 - loss 0.18191342 - samples/sec: 27.84 - lr: 0.000005\n",
      "2025-03-09 02:56:08,707 epoch 2 - iter 450/500 - loss 0.17589324 - samples/sec: 27.72 - lr: 0.000005\n",
      "2025-03-09 02:56:15,828 epoch 2 - iter 500/500 - loss 0.17167135 - samples/sec: 29.51 - lr: 0.000004\n",
      "2025-03-09 02:56:16,076 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:56:16,076 EPOCH 2 done: loss 0.1717 - lr 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 21.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:56:21,831 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:56:21,838 DEV : loss 0.12635788321495056 - f1-score (micro avg)  0.776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:56:22,111 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:56:27,177 saving best model\n",
      "2025-03-09 02:56:32,193 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:56:40,104 epoch 3 - iter 50/500 - loss 0.08248246 - samples/sec: 25.63 - lr: 0.000004\n",
      "2025-03-09 02:56:47,456 epoch 3 - iter 100/500 - loss 0.09465222 - samples/sec: 28.58 - lr: 0.000004\n",
      "2025-03-09 02:56:55,601 epoch 3 - iter 150/500 - loss 0.09759991 - samples/sec: 25.68 - lr: 0.000004\n",
      "2025-03-09 02:57:03,193 epoch 3 - iter 200/500 - loss 0.10460970 - samples/sec: 27.64 - lr: 0.000004\n",
      "2025-03-09 02:57:10,596 epoch 3 - iter 250/500 - loss 0.10144229 - samples/sec: 28.34 - lr: 0.000004\n",
      "2025-03-09 02:57:18,090 epoch 3 - iter 300/500 - loss 0.10006553 - samples/sec: 27.99 - lr: 0.000004\n",
      "2025-03-09 02:57:25,459 epoch 3 - iter 350/500 - loss 0.09616156 - samples/sec: 28.47 - lr: 0.000004\n",
      "2025-03-09 02:57:33,220 epoch 3 - iter 400/500 - loss 0.09915457 - samples/sec: 26.98 - lr: 0.000004\n",
      "2025-03-09 02:57:40,933 epoch 3 - iter 450/500 - loss 0.09788565 - samples/sec: 27.18 - lr: 0.000004\n",
      "2025-03-09 02:57:48,306 epoch 3 - iter 500/500 - loss 0.09814738 - samples/sec: 28.47 - lr: 0.000004\n",
      "2025-03-09 02:57:48,554 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:57:48,554 EPOCH 3 done: loss 0.0981 - lr 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 21.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:57:54,286 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:57:54,294 DEV : loss 0.16065356135368347 - f1-score (micro avg)  0.804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:57:54,850 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:57:59,754 saving best model\n",
      "2025-03-09 02:58:04,624 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:58:11,730 epoch 4 - iter 50/500 - loss 0.06264683 - samples/sec: 28.57 - lr: 0.000004\n",
      "2025-03-09 02:58:18,843 epoch 4 - iter 100/500 - loss 0.05155066 - samples/sec: 29.55 - lr: 0.000004\n",
      "2025-03-09 02:58:26,386 epoch 4 - iter 150/500 - loss 0.04769386 - samples/sec: 27.81 - lr: 0.000004\n",
      "2025-03-09 02:58:34,359 epoch 4 - iter 200/500 - loss 0.05228512 - samples/sec: 26.25 - lr: 0.000004\n",
      "2025-03-09 02:58:41,493 epoch 4 - iter 250/500 - loss 0.05275952 - samples/sec: 29.48 - lr: 0.000004\n",
      "2025-03-09 02:58:49,245 epoch 4 - iter 300/500 - loss 0.04846530 - samples/sec: 26.99 - lr: 0.000004\n",
      "2025-03-09 02:58:56,978 epoch 4 - iter 350/500 - loss 0.04965688 - samples/sec: 27.10 - lr: 0.000004\n",
      "2025-03-09 02:59:04,945 epoch 4 - iter 400/500 - loss 0.05132355 - samples/sec: 26.26 - lr: 0.000003\n",
      "2025-03-09 02:59:12,650 epoch 4 - iter 450/500 - loss 0.05311086 - samples/sec: 27.21 - lr: 0.000003\n",
      "2025-03-09 02:59:20,677 epoch 4 - iter 500/500 - loss 0.05225459 - samples/sec: 26.06 - lr: 0.000003\n",
      "2025-03-09 02:59:20,925 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:59:20,926 EPOCH 4 done: loss 0.0523 - lr 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 21.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:59:26,643 Evaluating as a multi-label problem: False\n",
      "2025-03-09 02:59:26,651 DEV : loss 0.21514379978179932 - f1-score (micro avg)  0.794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 02:59:27,245 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 02:59:32,153 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 02:59:39,331 epoch 5 - iter 50/500 - loss 0.02274053 - samples/sec: 28.29 - lr: 0.000003\n",
      "2025-03-09 02:59:46,652 epoch 5 - iter 100/500 - loss 0.01475410 - samples/sec: 28.70 - lr: 0.000003\n",
      "2025-03-09 02:59:54,019 epoch 5 - iter 150/500 - loss 0.01952765 - samples/sec: 28.50 - lr: 0.000003\n",
      "2025-03-09 03:00:01,757 epoch 5 - iter 200/500 - loss 0.01898554 - samples/sec: 27.08 - lr: 0.000003\n",
      "2025-03-09 03:00:09,357 epoch 5 - iter 250/500 - loss 0.02443609 - samples/sec: 27.61 - lr: 0.000003\n",
      "2025-03-09 03:00:17,526 epoch 5 - iter 300/500 - loss 0.02998129 - samples/sec: 25.59 - lr: 0.000003\n",
      "2025-03-09 03:00:24,764 epoch 5 - iter 350/500 - loss 0.02992507 - samples/sec: 29.01 - lr: 0.000003\n",
      "2025-03-09 03:00:32,159 epoch 5 - iter 400/500 - loss 0.03066500 - samples/sec: 28.43 - lr: 0.000003\n",
      "2025-03-09 03:00:39,478 epoch 5 - iter 450/500 - loss 0.03066792 - samples/sec: 28.67 - lr: 0.000003\n",
      "2025-03-09 03:00:47,780 epoch 5 - iter 500/500 - loss 0.03055189 - samples/sec: 25.15 - lr: 0.000003\n",
      "2025-03-09 03:00:48,026 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:00:48,026 EPOCH 5 done: loss 0.0306 - lr 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 21.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:00:53,770 Evaluating as a multi-label problem: False\n",
      "2025-03-09 03:00:53,778 DEV : loss 0.2804914712905884 - f1-score (micro avg)  0.794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:00:54,048 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 03:00:58,950 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:01:06,417 epoch 6 - iter 50/500 - loss 0.02168673 - samples/sec: 27.18 - lr: 0.000003\n",
      "2025-03-09 03:01:13,921 epoch 6 - iter 100/500 - loss 0.01543846 - samples/sec: 27.97 - lr: 0.000003\n",
      "2025-03-09 03:01:21,315 epoch 6 - iter 150/500 - loss 0.01283153 - samples/sec: 28.40 - lr: 0.000003\n",
      "2025-03-09 03:01:28,693 epoch 6 - iter 200/500 - loss 0.01552602 - samples/sec: 28.47 - lr: 0.000003\n",
      "2025-03-09 03:01:36,173 epoch 6 - iter 250/500 - loss 0.01463585 - samples/sec: 28.04 - lr: 0.000003\n",
      "2025-03-09 03:01:43,411 epoch 6 - iter 300/500 - loss 0.01416336 - samples/sec: 29.01 - lr: 0.000002\n",
      "2025-03-09 03:01:51,297 epoch 6 - iter 350/500 - loss 0.01349876 - samples/sec: 26.53 - lr: 0.000002\n",
      "2025-03-09 03:01:59,213 epoch 6 - iter 400/500 - loss 0.01451000 - samples/sec: 26.45 - lr: 0.000002\n",
      "2025-03-09 03:02:06,786 epoch 6 - iter 450/500 - loss 0.01735849 - samples/sec: 27.70 - lr: 0.000002\n",
      "2025-03-09 03:02:14,117 epoch 6 - iter 500/500 - loss 0.01696967 - samples/sec: 28.64 - lr: 0.000002\n",
      "2025-03-09 03:02:14,371 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:02:14,371 EPOCH 6 done: loss 0.0170 - lr 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 21.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:02:20,095 Evaluating as a multi-label problem: False\n",
      "2025-03-09 03:02:20,103 DEV : loss 0.29091155529022217 - f1-score (micro avg)  0.81\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:02:20,372 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 03:02:25,263 saving best model\n",
      "2025-03-09 03:02:30,315 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:02:37,299 epoch 7 - iter 50/500 - loss 0.00343085 - samples/sec: 29.08 - lr: 0.000002\n",
      "2025-03-09 03:02:44,757 epoch 7 - iter 100/500 - loss 0.00726025 - samples/sec: 28.15 - lr: 0.000002\n",
      "2025-03-09 03:02:52,408 epoch 7 - iter 150/500 - loss 0.00956498 - samples/sec: 27.40 - lr: 0.000002\n",
      "2025-03-09 03:03:00,402 epoch 7 - iter 200/500 - loss 0.00976475 - samples/sec: 26.17 - lr: 0.000002\n",
      "2025-03-09 03:03:08,265 epoch 7 - iter 250/500 - loss 0.00916973 - samples/sec: 26.61 - lr: 0.000002\n",
      "2025-03-09 03:03:16,207 epoch 7 - iter 300/500 - loss 0.00963570 - samples/sec: 26.36 - lr: 0.000002\n",
      "2025-03-09 03:03:23,877 epoch 7 - iter 350/500 - loss 0.00959552 - samples/sec: 27.31 - lr: 0.000002\n",
      "2025-03-09 03:03:31,749 epoch 7 - iter 400/500 - loss 0.01062457 - samples/sec: 26.59 - lr: 0.000002\n",
      "2025-03-09 03:03:39,067 epoch 7 - iter 450/500 - loss 0.01065765 - samples/sec: 28.68 - lr: 0.000002\n",
      "2025-03-09 03:03:47,022 epoch 7 - iter 500/500 - loss 0.00999976 - samples/sec: 26.41 - lr: 0.000002\n",
      "2025-03-09 03:03:47,271 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:03:47,272 EPOCH 7 done: loss 0.0100 - lr 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 21.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:03:53,053 Evaluating as a multi-label problem: False\n",
      "2025-03-09 03:03:53,060 DEV : loss 0.3562854826450348 - f1-score (micro avg)  0.796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:03:53,333 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 03:03:58,225 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:04:05,997 epoch 8 - iter 50/500 - loss 0.00055276 - samples/sec: 26.10 - lr: 0.000002\n",
      "2025-03-09 03:04:13,909 epoch 8 - iter 100/500 - loss 0.00109424 - samples/sec: 26.43 - lr: 0.000002\n",
      "2025-03-09 03:04:21,521 epoch 8 - iter 150/500 - loss 0.00281292 - samples/sec: 27.55 - lr: 0.000002\n",
      "2025-03-09 03:04:29,017 epoch 8 - iter 200/500 - loss 0.00321801 - samples/sec: 27.97 - lr: 0.000001\n",
      "2025-03-09 03:04:36,173 epoch 8 - iter 250/500 - loss 0.00278502 - samples/sec: 29.36 - lr: 0.000001\n",
      "2025-03-09 03:04:43,696 epoch 8 - iter 300/500 - loss 0.00358684 - samples/sec: 27.88 - lr: 0.000001\n",
      "2025-03-09 03:04:51,890 epoch 8 - iter 350/500 - loss 0.00391596 - samples/sec: 25.50 - lr: 0.000001\n",
      "2025-03-09 03:04:59,653 epoch 8 - iter 400/500 - loss 0.00348177 - samples/sec: 26.97 - lr: 0.000001\n",
      "2025-03-09 03:05:07,444 epoch 8 - iter 450/500 - loss 0.00403567 - samples/sec: 26.89 - lr: 0.000001\n",
      "2025-03-09 03:05:14,607 epoch 8 - iter 500/500 - loss 0.00466068 - samples/sec: 29.32 - lr: 0.000001\n",
      "2025-03-09 03:05:14,856 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:05:14,856 EPOCH 8 done: loss 0.0047 - lr 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 21.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:05:20,607 Evaluating as a multi-label problem: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:05:20,615 DEV : loss 0.3330846428871155 - f1-score (micro avg)  0.808\n",
      "2025-03-09 03:05:21,173 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 03:05:26,096 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:05:33,678 epoch 9 - iter 50/500 - loss 0.00494890 - samples/sec: 26.78 - lr: 0.000001\n",
      "2025-03-09 03:05:41,315 epoch 9 - iter 100/500 - loss 0.00415358 - samples/sec: 27.49 - lr: 0.000001\n",
      "2025-03-09 03:05:49,038 epoch 9 - iter 150/500 - loss 0.00381157 - samples/sec: 27.13 - lr: 0.000001\n",
      "2025-03-09 03:05:56,199 epoch 9 - iter 200/500 - loss 0.00460687 - samples/sec: 29.33 - lr: 0.000001\n",
      "2025-03-09 03:06:04,044 epoch 9 - iter 250/500 - loss 0.00377010 - samples/sec: 26.71 - lr: 0.000001\n",
      "2025-03-09 03:06:11,630 epoch 9 - iter 300/500 - loss 0.00317406 - samples/sec: 27.62 - lr: 0.000001\n",
      "2025-03-09 03:06:18,987 epoch 9 - iter 350/500 - loss 0.00303888 - samples/sec: 28.55 - lr: 0.000001\n",
      "2025-03-09 03:06:26,808 epoch 9 - iter 400/500 - loss 0.00379151 - samples/sec: 26.87 - lr: 0.000001\n",
      "2025-03-09 03:06:34,310 epoch 9 - iter 450/500 - loss 0.00339485 - samples/sec: 27.97 - lr: 0.000001\n",
      "2025-03-09 03:06:42,154 epoch 9 - iter 500/500 - loss 0.00312312 - samples/sec: 26.69 - lr: 0.000001\n",
      "2025-03-09 03:06:42,404 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:06:42,405 EPOCH 9 done: loss 0.0031 - lr 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 21.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:06:48,235 Evaluating as a multi-label problem: False\n",
      "2025-03-09 03:06:48,243 DEV : loss 0.36564967036247253 - f1-score (micro avg)  0.806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:06:48,831 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 03:06:53,746 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:07:01,320 epoch 10 - iter 50/500 - loss 0.00024576 - samples/sec: 26.81 - lr: 0.000001\n",
      "2025-03-09 03:07:09,037 epoch 10 - iter 100/500 - loss 0.00020678 - samples/sec: 27.14 - lr: 0.000000\n",
      "2025-03-09 03:07:16,755 epoch 10 - iter 150/500 - loss 0.00165061 - samples/sec: 27.15 - lr: 0.000000\n",
      "2025-03-09 03:07:24,331 epoch 10 - iter 200/500 - loss 0.00130773 - samples/sec: 27.67 - lr: 0.000000\n",
      "2025-03-09 03:07:31,655 epoch 10 - iter 250/500 - loss 0.00201104 - samples/sec: 28.65 - lr: 0.000000\n",
      "2025-03-09 03:07:39,632 epoch 10 - iter 300/500 - loss 0.00184530 - samples/sec: 26.25 - lr: 0.000000\n",
      "2025-03-09 03:07:47,210 epoch 10 - iter 350/500 - loss 0.00280645 - samples/sec: 27.65 - lr: 0.000000\n",
      "2025-03-09 03:07:54,703 epoch 10 - iter 400/500 - loss 0.00310394 - samples/sec: 28.02 - lr: 0.000000\n",
      "2025-03-09 03:08:02,327 epoch 10 - iter 450/500 - loss 0.00372203 - samples/sec: 27.51 - lr: 0.000000\n",
      "2025-03-09 03:08:10,292 epoch 10 - iter 500/500 - loss 0.00410847 - samples/sec: 26.25 - lr: 0.000000\n",
      "2025-03-09 03:08:10,539 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:08:10,539 EPOCH 10 done: loss 0.0041 - lr 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 21.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:08:16,276 Evaluating as a multi-label problem: False\n",
      "2025-03-09 03:08:16,284 DEV : loss 0.36126160621643066 - f1-score (micro avg)  0.808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:08:16,558 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 03:08:21,432 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:08:21,435 loading file logs/PDSC_V2/GELECTRA/G29B/3K/k4/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 23.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:08:39,711 Evaluating as a multi-label problem: False\n",
      "2025-03-09 03:08:39,719 0.85\t0.85\t0.85\t0.85\n",
      "2025-03-09 03:08:39,719 \n",
      "Results:\n",
      "- F-score (micro) 0.85\n",
      "- F-score (macro) 0.85\n",
      "- Accuracy 0.85\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       PSEUD     0.8378    0.8680    0.8527       250\n",
      "        ORIG     0.8631    0.8320    0.8473       250\n",
      "\n",
      "    accuracy                         0.8500       500\n",
      "   macro avg     0.8505    0.8500    0.8500       500\n",
      "weighted avg     0.8505    0.8500    0.8500       500\n",
      "\n",
      "2025-03-09 03:08:39,720 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:08:39,959 Reading data from tmp_data_dir\n",
      "2025-03-09 03:08:39,960 Train: tmp_data_dir/train.csv\n",
      "2025-03-09 03:08:39,961 Dev: tmp_data_dir/dev.csv\n",
      "2025-03-09 03:08:39,961 Test: tmp_data_dir/test.csv\n",
      "2025-03-09 03:08:39,973 Computing label dictionary. Progress:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2000it [00:01, 1929.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:08:41,012 Dictionary created for label 'label' with 3 values: ORIG (seen 1000 times), PSEUD (seen 1000 times)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "/home/s81481/pseugc/lib/python3.9/site-packages/transformers/modeling_utils.py:349: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:08:47,997 tensorboard logging path is logs/PDSC_V2/GELECTRA/G29B/3K/k5\n",
      "2025-03-09 03:08:48,005 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:08:48,007 Model: \"TextClassifier(\n",
      "  (decoder): Linear(in_features=1024, out_features=3, bias=True)\n",
      "  (dropout): Dropout(p=0.0, inplace=False)\n",
      "  (locked_dropout): LockedDropout(p=0.0)\n",
      "  (word_dropout): WordDropout(p=0.0)\n",
      "  (loss_function): CrossEntropyLoss()\n",
      "  (document_embeddings): TransformerDocumentEmbeddings(\n",
      "    (model): ElectraModel(\n",
      "      (embeddings): ElectraEmbeddings(\n",
      "        (word_embeddings): Embedding(31102, 1024, padding_idx=0)\n",
      "        (position_embeddings): Embedding(512, 1024)\n",
      "        (token_type_embeddings): Embedding(2, 1024)\n",
      "        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "      )\n",
      "      (encoder): ElectraEncoder(\n",
      "        (layer): ModuleList(\n",
      "          (0-23): 24 x ElectraLayer(\n",
      "            (attention): ElectraAttention(\n",
      "              (self): ElectraSelfAttention(\n",
      "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "              (output): ElectraSelfOutput(\n",
      "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
      "                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "                (dropout): Dropout(p=0.1, inplace=False)\n",
      "              )\n",
      "            )\n",
      "            (intermediate): ElectraIntermediate(\n",
      "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
      "              (intermediate_act_fn): GELUActivation()\n",
      "            )\n",
      "            (output): ElectraOutput(\n",
      "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
      "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
      "              (dropout): Dropout(p=0.1, inplace=False)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (weights): None\n",
      "  (weight_tensor) None\n",
      ")\"\n",
      "2025-03-09 03:08:48,007 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:08:48,007 Corpus: \"Corpus: 2000 train + 500 dev + 500 test sentences\"\n",
      "2025-03-09 03:08:48,008 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:08:48,008 Parameters:\n",
      "2025-03-09 03:08:48,008  - learning_rate: \"0.000005\"\n",
      "2025-03-09 03:08:48,009  - mini_batch_size: \"4\"\n",
      "2025-03-09 03:08:48,009  - patience: \"3\"\n",
      "2025-03-09 03:08:48,009  - anneal_factor: \"0.5\"\n",
      "2025-03-09 03:08:48,010  - max_epochs: \"10\"\n",
      "2025-03-09 03:08:48,010  - shuffle: \"True\"\n",
      "2025-03-09 03:08:48,010  - train_with_dev: \"False\"\n",
      "2025-03-09 03:08:48,010  - batch_growth_annealing: \"False\"\n",
      "2025-03-09 03:08:48,011 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:08:48,011 Model training base path: \"logs/PDSC_V2/GELECTRA/G29B/3K/k5\"\n",
      "2025-03-09 03:08:48,011 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:08:48,012 Device: cuda:0\n",
      "2025-03-09 03:08:48,012 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:08:48,012 Embeddings storage mode: none\n",
      "2025-03-09 03:08:48,012 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:08:55,600 epoch 1 - iter 50/500 - loss 0.45355386 - samples/sec: 26.75 - lr: 0.000001\n",
      "2025-03-09 03:09:03,512 epoch 1 - iter 100/500 - loss 0.34049397 - samples/sec: 26.57 - lr: 0.000001\n",
      "2025-03-09 03:09:11,105 epoch 1 - iter 150/500 - loss 0.23642118 - samples/sec: 27.61 - lr: 0.000002\n",
      "2025-03-09 03:09:19,030 epoch 1 - iter 200/500 - loss 0.17785186 - samples/sec: 26.43 - lr: 0.000002\n",
      "2025-03-09 03:09:26,423 epoch 1 - iter 250/500 - loss 0.14248297 - samples/sec: 28.38 - lr: 0.000003\n",
      "2025-03-09 03:09:34,051 epoch 1 - iter 300/500 - loss 0.18853149 - samples/sec: 27.50 - lr: 0.000003\n",
      "2025-03-09 03:09:42,316 epoch 1 - iter 350/500 - loss 0.16163733 - samples/sec: 25.29 - lr: 0.000003\n",
      "2025-03-09 03:09:49,845 epoch 1 - iter 400/500 - loss 0.14145155 - samples/sec: 27.86 - lr: 0.000004\n",
      "2025-03-09 03:09:58,271 epoch 1 - iter 450/500 - loss 0.12574596 - samples/sec: 24.81 - lr: 0.000005\n",
      "2025-03-09 03:10:05,736 epoch 1 - iter 500/500 - loss 0.11317938 - samples/sec: 28.08 - lr: 0.000005\n",
      "2025-03-09 03:10:05,982 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:10:05,982 EPOCH 1 done: loss 0.1132 - lr 0.000005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 24.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:10:11,110 Evaluating as a multi-label problem: False\n",
      "2025-03-09 03:10:11,118 DEV : loss 1.2460074424743652 - f1-score (micro avg)  0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:10:11,642 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 03:10:16,778 saving best model\n",
      "2025-03-09 03:10:23,554 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:10:30,639 epoch 2 - iter 50/500 - loss 0.28321111 - samples/sec: 28.66 - lr: 0.000005\n",
      "2025-03-09 03:10:38,382 epoch 2 - iter 100/500 - loss 0.23410798 - samples/sec: 27.06 - lr: 0.000005\n",
      "2025-03-09 03:10:46,382 epoch 2 - iter 150/500 - loss 0.21849653 - samples/sec: 26.16 - lr: 0.000005\n",
      "2025-03-09 03:10:54,465 epoch 2 - iter 200/500 - loss 0.21069441 - samples/sec: 25.88 - lr: 0.000005\n",
      "2025-03-09 03:11:01,638 epoch 2 - iter 250/500 - loss 0.20627667 - samples/sec: 29.29 - lr: 0.000005\n",
      "2025-03-09 03:11:09,689 epoch 2 - iter 300/500 - loss 0.20218890 - samples/sec: 26.00 - lr: 0.000005\n",
      "2025-03-09 03:11:17,766 epoch 2 - iter 350/500 - loss 0.19995203 - samples/sec: 25.87 - lr: 0.000005\n",
      "2025-03-09 03:11:25,789 epoch 2 - iter 400/500 - loss 0.19784771 - samples/sec: 26.09 - lr: 0.000005\n",
      "2025-03-09 03:11:33,663 epoch 2 - iter 450/500 - loss 0.19549116 - samples/sec: 26.61 - lr: 0.000005\n",
      "2025-03-09 03:11:41,007 epoch 2 - iter 500/500 - loss 0.19414623 - samples/sec: 28.58 - lr: 0.000004\n",
      "2025-03-09 03:11:41,254 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:11:41,255 EPOCH 2 done: loss 0.1941 - lr 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 23.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:11:46,682 Evaluating as a multi-label problem: False\n",
      "2025-03-09 03:11:46,689 DEV : loss 0.17325349152088165 - f1-score (micro avg)  0.524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:11:46,945 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 03:11:51,971 saving best model\n",
      "2025-03-09 03:11:56,839 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:12:04,409 epoch 3 - iter 50/500 - loss 0.17542849 - samples/sec: 26.84 - lr: 0.000004\n",
      "2025-03-09 03:12:12,225 epoch 3 - iter 100/500 - loss 0.17712977 - samples/sec: 26.81 - lr: 0.000004\n",
      "2025-03-09 03:12:20,164 epoch 3 - iter 150/500 - loss 0.17663798 - samples/sec: 26.36 - lr: 0.000004\n",
      "2025-03-09 03:12:27,885 epoch 3 - iter 200/500 - loss 0.17722882 - samples/sec: 27.14 - lr: 0.000004\n",
      "2025-03-09 03:12:35,799 epoch 3 - iter 250/500 - loss 0.17654867 - samples/sec: 26.44 - lr: 0.000004\n",
      "2025-03-09 03:12:43,477 epoch 3 - iter 300/500 - loss 0.17648666 - samples/sec: 27.30 - lr: 0.000004\n",
      "2025-03-09 03:12:51,061 epoch 3 - iter 350/500 - loss 0.17576622 - samples/sec: 27.62 - lr: 0.000004\n",
      "2025-03-09 03:12:59,321 epoch 3 - iter 400/500 - loss 0.17605150 - samples/sec: 25.27 - lr: 0.000004\n",
      "2025-03-09 03:13:07,198 epoch 3 - iter 450/500 - loss 0.17612238 - samples/sec: 26.58 - lr: 0.000004\n",
      "2025-03-09 03:13:15,216 epoch 3 - iter 500/500 - loss 0.17543625 - samples/sec: 26.09 - lr: 0.000004\n",
      "2025-03-09 03:13:15,463 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:13:15,464 EPOCH 3 done: loss 0.1754 - lr 0.000004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 24.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:13:20,583 Evaluating as a multi-label problem: False\n",
      "2025-03-09 03:13:20,590 DEV : loss 0.16934840381145477 - f1-score (micro avg)  0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:13:20,846 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 03:13:25,853 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:13:33,516 epoch 4 - iter 50/500 - loss 0.15574467 - samples/sec: 26.49 - lr: 0.000004\n",
      "2025-03-09 03:13:41,458 epoch 4 - iter 100/500 - loss 0.15347760 - samples/sec: 26.39 - lr: 0.000004\n",
      "2025-03-09 03:13:49,149 epoch 4 - iter 150/500 - loss 0.15278456 - samples/sec: 27.24 - lr: 0.000004\n",
      "2025-03-09 03:13:56,498 epoch 4 - iter 200/500 - loss 0.14863610 - samples/sec: 28.55 - lr: 0.000004\n",
      "2025-03-09 03:14:04,648 epoch 4 - iter 250/500 - loss 0.14460188 - samples/sec: 25.66 - lr: 0.000004\n",
      "2025-03-09 03:14:11,984 epoch 4 - iter 300/500 - loss 0.13939014 - samples/sec: 28.61 - lr: 0.000004\n",
      "2025-03-09 03:14:20,137 epoch 4 - iter 350/500 - loss 0.13441942 - samples/sec: 25.64 - lr: 0.000004\n",
      "2025-03-09 03:14:27,837 epoch 4 - iter 400/500 - loss 0.13016391 - samples/sec: 27.22 - lr: 0.000003\n",
      "2025-03-09 03:14:35,512 epoch 4 - iter 450/500 - loss 0.13054461 - samples/sec: 27.32 - lr: 0.000003\n",
      "2025-03-09 03:14:43,657 epoch 4 - iter 500/500 - loss 0.12897373 - samples/sec: 25.67 - lr: 0.000003\n",
      "2025-03-09 03:14:43,904 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:14:43,905 EPOCH 4 done: loss 0.1290 - lr 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 24.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:14:49,034 Evaluating as a multi-label problem: False\n",
      "2025-03-09 03:14:49,042 DEV : loss 0.15144293010234833 - f1-score (micro avg)  0.796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:14:49,302 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 03:14:54,367 saving best model\n",
      "2025-03-09 03:14:59,326 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:15:06,994 epoch 5 - iter 50/500 - loss 0.05510845 - samples/sec: 26.48 - lr: 0.000003\n",
      "2025-03-09 03:15:14,894 epoch 5 - iter 100/500 - loss 0.08141910 - samples/sec: 26.49 - lr: 0.000003\n",
      "2025-03-09 03:15:22,875 epoch 5 - iter 150/500 - loss 0.08127576 - samples/sec: 26.24 - lr: 0.000003\n",
      "2025-03-09 03:15:30,819 epoch 5 - iter 200/500 - loss 0.08057107 - samples/sec: 26.34 - lr: 0.000003\n",
      "2025-03-09 03:15:38,928 epoch 5 - iter 250/500 - loss 0.07286670 - samples/sec: 25.79 - lr: 0.000003\n",
      "2025-03-09 03:15:46,682 epoch 5 - iter 300/500 - loss 0.07625801 - samples/sec: 26.99 - lr: 0.000003\n",
      "2025-03-09 03:15:54,375 epoch 5 - iter 350/500 - loss 0.07482140 - samples/sec: 27.22 - lr: 0.000003\n",
      "2025-03-09 03:16:02,337 epoch 5 - iter 400/500 - loss 0.07280247 - samples/sec: 26.30 - lr: 0.000003\n",
      "2025-03-09 03:16:10,170 epoch 5 - iter 450/500 - loss 0.07532447 - samples/sec: 26.79 - lr: 0.000003\n",
      "2025-03-09 03:16:17,716 epoch 5 - iter 500/500 - loss 0.07377829 - samples/sec: 27.79 - lr: 0.000003\n",
      "2025-03-09 03:16:17,962 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:16:17,963 EPOCH 5 done: loss 0.0738 - lr 0.000003\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 24.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:16:23,084 Evaluating as a multi-label problem: False\n",
      "2025-03-09 03:16:23,093 DEV : loss 0.1447685807943344 - f1-score (micro avg)  0.85\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:16:23,647 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 03:16:28,725 saving best model\n",
      "2025-03-09 03:16:33,632 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:16:41,433 epoch 6 - iter 50/500 - loss 0.03735685 - samples/sec: 26.02 - lr: 0.000003\n",
      "2025-03-09 03:16:48,772 epoch 6 - iter 100/500 - loss 0.04406414 - samples/sec: 28.60 - lr: 0.000003\n",
      "2025-03-09 03:16:56,211 epoch 6 - iter 150/500 - loss 0.04489136 - samples/sec: 28.22 - lr: 0.000003\n",
      "2025-03-09 03:17:03,776 epoch 6 - iter 200/500 - loss 0.04620665 - samples/sec: 27.72 - lr: 0.000003\n",
      "2025-03-09 03:17:11,544 epoch 6 - iter 250/500 - loss 0.04925480 - samples/sec: 26.95 - lr: 0.000003\n",
      "2025-03-09 03:17:19,625 epoch 6 - iter 300/500 - loss 0.04936539 - samples/sec: 25.88 - lr: 0.000002\n",
      "2025-03-09 03:17:27,484 epoch 6 - iter 350/500 - loss 0.04678524 - samples/sec: 26.63 - lr: 0.000002\n",
      "2025-03-09 03:17:35,216 epoch 6 - iter 400/500 - loss 0.04631672 - samples/sec: 27.11 - lr: 0.000002\n",
      "2025-03-09 03:17:43,311 epoch 6 - iter 450/500 - loss 0.04484162 - samples/sec: 25.85 - lr: 0.000002\n",
      "2025-03-09 03:17:51,271 epoch 6 - iter 500/500 - loss 0.04659037 - samples/sec: 26.30 - lr: 0.000002\n",
      "2025-03-09 03:17:51,520 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:17:51,521 EPOCH 6 done: loss 0.0466 - lr 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 24.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:17:56,643 Evaluating as a multi-label problem: False\n",
      "2025-03-09 03:17:56,651 DEV : loss 0.14727164804935455 - f1-score (micro avg)  0.868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:17:57,230 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 03:18:02,269 saving best model\n",
      "2025-03-09 03:18:07,152 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:18:14,842 epoch 7 - iter 50/500 - loss 0.02007418 - samples/sec: 26.38 - lr: 0.000002\n",
      "2025-03-09 03:18:22,237 epoch 7 - iter 100/500 - loss 0.02633195 - samples/sec: 28.37 - lr: 0.000002\n",
      "2025-03-09 03:18:30,461 epoch 7 - iter 150/500 - loss 0.02566188 - samples/sec: 25.41 - lr: 0.000002\n",
      "2025-03-09 03:18:38,465 epoch 7 - iter 200/500 - loss 0.02707551 - samples/sec: 26.15 - lr: 0.000002\n",
      "2025-03-09 03:18:46,146 epoch 7 - iter 250/500 - loss 0.02675634 - samples/sec: 27.27 - lr: 0.000002\n",
      "2025-03-09 03:18:53,835 epoch 7 - iter 300/500 - loss 0.02398688 - samples/sec: 27.25 - lr: 0.000002\n",
      "2025-03-09 03:19:01,594 epoch 7 - iter 350/500 - loss 0.02249460 - samples/sec: 27.03 - lr: 0.000002\n",
      "2025-03-09 03:19:09,501 epoch 7 - iter 400/500 - loss 0.02307178 - samples/sec: 26.46 - lr: 0.000002\n",
      "2025-03-09 03:19:17,387 epoch 7 - iter 450/500 - loss 0.02447444 - samples/sec: 26.56 - lr: 0.000002\n",
      "2025-03-09 03:19:25,718 epoch 7 - iter 500/500 - loss 0.02392348 - samples/sec: 25.11 - lr: 0.000002\n",
      "2025-03-09 03:19:25,964 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:19:25,964 EPOCH 7 done: loss 0.0239 - lr 0.000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 24.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:19:31,078 Evaluating as a multi-label problem: False\n",
      "2025-03-09 03:19:31,085 DEV : loss 0.187855526804924 - f1-score (micro avg)  0.874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:19:31,340 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 03:19:36,408 saving best model\n",
      "2025-03-09 03:19:41,405 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:19:49,281 epoch 8 - iter 50/500 - loss 0.02647776 - samples/sec: 25.75 - lr: 0.000002\n",
      "2025-03-09 03:19:56,864 epoch 8 - iter 100/500 - loss 0.02314758 - samples/sec: 27.71 - lr: 0.000002\n",
      "2025-03-09 03:20:04,687 epoch 8 - iter 150/500 - loss 0.01582190 - samples/sec: 26.77 - lr: 0.000002\n",
      "2025-03-09 03:20:12,107 epoch 8 - iter 200/500 - loss 0.01400460 - samples/sec: 28.27 - lr: 0.000001\n",
      "2025-03-09 03:20:19,682 epoch 8 - iter 250/500 - loss 0.01288645 - samples/sec: 27.67 - lr: 0.000001\n",
      "2025-03-09 03:20:27,711 epoch 8 - iter 300/500 - loss 0.01294674 - samples/sec: 26.05 - lr: 0.000001\n",
      "2025-03-09 03:20:36,093 epoch 8 - iter 350/500 - loss 0.01248877 - samples/sec: 25.85 - lr: 0.000001\n",
      "2025-03-09 03:20:43,775 epoch 8 - iter 400/500 - loss 0.01205569 - samples/sec: 27.27 - lr: 0.000001\n",
      "2025-03-09 03:20:51,303 epoch 8 - iter 450/500 - loss 0.01559626 - samples/sec: 27.88 - lr: 0.000001\n",
      "2025-03-09 03:20:58,957 epoch 8 - iter 500/500 - loss 0.01796079 - samples/sec: 27.56 - lr: 0.000001\n",
      "2025-03-09 03:20:59,205 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:20:59,205 EPOCH 8 done: loss 0.0180 - lr 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 24.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:21:04,352 Evaluating as a multi-label problem: False\n",
      "2025-03-09 03:21:04,360 DEV : loss 0.2120482623577118 - f1-score (micro avg)  0.856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:21:04,621 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 03:21:09,674 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:21:17,219 epoch 9 - iter 50/500 - loss 0.00876841 - samples/sec: 26.89 - lr: 0.000001\n",
      "2025-03-09 03:21:25,040 epoch 9 - iter 100/500 - loss 0.02042541 - samples/sec: 26.79 - lr: 0.000001\n",
      "2025-03-09 03:21:32,513 epoch 9 - iter 150/500 - loss 0.01960203 - samples/sec: 28.06 - lr: 0.000001\n",
      "2025-03-09 03:21:40,766 epoch 9 - iter 200/500 - loss 0.01510279 - samples/sec: 25.33 - lr: 0.000001\n",
      "2025-03-09 03:21:48,907 epoch 9 - iter 250/500 - loss 0.01438247 - samples/sec: 25.69 - lr: 0.000001\n",
      "2025-03-09 03:21:56,668 epoch 9 - iter 300/500 - loss 0.01209541 - samples/sec: 26.97 - lr: 0.000001\n",
      "2025-03-09 03:22:04,349 epoch 9 - iter 350/500 - loss 0.01213079 - samples/sec: 27.29 - lr: 0.000001\n",
      "2025-03-09 03:22:12,303 epoch 9 - iter 400/500 - loss 0.01070029 - samples/sec: 26.31 - lr: 0.000001\n",
      "2025-03-09 03:22:19,813 epoch 9 - iter 450/500 - loss 0.01037550 - samples/sec: 27.95 - lr: 0.000001\n",
      "2025-03-09 03:22:27,579 epoch 9 - iter 500/500 - loss 0.01099838 - samples/sec: 26.97 - lr: 0.000001\n",
      "2025-03-09 03:22:27,830 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:22:27,830 EPOCH 9 done: loss 0.0110 - lr 0.000001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 24.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:22:33,003 Evaluating as a multi-label problem: False\n",
      "2025-03-09 03:22:33,011 DEV : loss 0.24829865992069244 - f1-score (micro avg)  0.846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:22:33,271 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 03:22:38,364 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:22:45,850 epoch 10 - iter 50/500 - loss 0.01320022 - samples/sec: 27.11 - lr: 0.000001\n",
      "2025-03-09 03:22:53,570 epoch 10 - iter 100/500 - loss 0.00814225 - samples/sec: 27.14 - lr: 0.000000\n",
      "2025-03-09 03:23:01,284 epoch 10 - iter 150/500 - loss 0.00715945 - samples/sec: 27.15 - lr: 0.000000\n",
      "2025-03-09 03:23:09,139 epoch 10 - iter 200/500 - loss 0.00706120 - samples/sec: 26.65 - lr: 0.000000\n",
      "2025-03-09 03:23:17,149 epoch 10 - iter 250/500 - loss 0.00682371 - samples/sec: 26.15 - lr: 0.000000\n",
      "2025-03-09 03:23:24,849 epoch 10 - iter 300/500 - loss 0.00948452 - samples/sec: 27.23 - lr: 0.000000\n",
      "2025-03-09 03:23:32,288 epoch 10 - iter 350/500 - loss 0.00976867 - samples/sec: 28.23 - lr: 0.000000\n",
      "2025-03-09 03:23:40,229 epoch 10 - iter 400/500 - loss 0.00955585 - samples/sec: 26.34 - lr: 0.000000\n",
      "2025-03-09 03:23:47,933 epoch 10 - iter 450/500 - loss 0.00854233 - samples/sec: 27.20 - lr: 0.000000\n",
      "2025-03-09 03:23:56,016 epoch 10 - iter 500/500 - loss 0.00841826 - samples/sec: 25.89 - lr: 0.000000\n",
      "2025-03-09 03:23:56,262 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:23:56,263 EPOCH 10 done: loss 0.0084 - lr 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 24.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:24:01,377 Evaluating as a multi-label problem: False\n",
      "2025-03-09 03:24:01,385 DEV : loss 0.23265114426612854 - f1-score (micro avg)  0.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:24:01,932 BAD EPOCHS (no improvement): 4\n",
      "2025-03-09 03:24:07,047 ----------------------------------------------------------------------------------------------------\n",
      "2025-03-09 03:24:07,050 loading file logs/PDSC_V2/GELECTRA/G29B/3K/k5/best-model.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████| 125/125 [00:05<00:00, 23.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-09 03:24:25,258 Evaluating as a multi-label problem: False\n",
      "2025-03-09 03:24:25,266 0.846\t0.846\t0.846\t0.846\n",
      "2025-03-09 03:24:25,267 \n",
      "Results:\n",
      "- F-score (micro) 0.846\n",
      "- F-score (macro) 0.8456\n",
      "- Accuracy 0.846\n",
      "\n",
      "By class:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       PSEUD     0.8145    0.8960    0.8533       250\n",
      "        ORIG     0.8844    0.7960    0.8379       250\n",
      "\n",
      "    accuracy                         0.8460       500\n",
      "   macro avg     0.8495    0.8460    0.8456       500\n",
      "weighted avg     0.8495    0.8460    0.8456       500\n",
      "\n",
      "2025-03-09 03:24:25,267 ----------------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 5):\n",
    "    k = i + 1\n",
    "    \n",
    "    syntheticity_data = pd.read_csv(f\"data_syntheticity_dataset_3000_{model_tag}.csv\", index_col=0)\n",
    "    dataset = cdp_2022.get_train_dev_test_datasetdict_for_syntheticity_dataset(syntheticity_data, 500, k)\n",
    "\n",
    "    train_df = dataset[\"train\"].to_pandas()\n",
    "    dev_df = dataset[\"dev\"].to_pandas()\n",
    "    test_df = dataset[\"test\"].to_pandas()\n",
    "    \n",
    "    tmp_data_dir = Path(\"tmp_data_dir\")\n",
    "    tmp_data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    for file in tmp_data_dir.glob(\"*\"):\n",
    "        if file.is_file():\n",
    "            file.unlink()\n",
    "    \n",
    "    model_dir_path = os.path.join(*[\"logs\", \"PDSC\", \"GELECTRA\", model_tag, str(len(syntheticity_data)//1000)+\"K\", \"k\"+str(k)])\n",
    "    os.makedirs(model_dir_path, exist_ok=True)\n",
    "    \n",
    "    corpus: Corpus = prepare_flair_corpus(data_folder=tmp_data_dir)\n",
    "    label_dict: Dictionary = corpus.make_label_dictionary(label_type=\"label\")\n",
    "    classifier = TextClassifier(\n",
    "        document_embeddings=TransformerDocumentEmbeddings('deepset/gelectra-large', fine_tune=True),\n",
    "        label_dictionary=label_dict,\n",
    "        label_type='label',\n",
    "        multi_label=False\n",
    "    )\n",
    "    trainer: ModelTrainer = ModelTrainer(classifier, corpus)\n",
    "    trainer.fine_tune(\n",
    "        model_dir_path,\n",
    "        learning_rate=5.0e-6,\n",
    "        mini_batch_size=4,\n",
    "        max_epochs=10,\n",
    "        checkpoint=True,\n",
    "        write_weights=True,\n",
    "        use_tensorboard=True,\n",
    "        tensorboard_log_dir=model_dir_path,\n",
    "        save_final_model=False,\n",
    "        use_final_model_for_eval=False\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
