{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 858,
   "id": "e9d2f582",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Jan 26 21:06:50 2025       \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 550.127.08             Driver Version: 550.127.08     CUDA Version: 12.4     |\r\n",
      "|-----------------------------------------+------------------------+----------------------+\r\n",
      "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|                                         |                        |               MIG M. |\r\n",
      "|=========================================+========================+======================|\r\n",
      "|   0  NVIDIA A100-SXM4-40GB          On  |   00000000:47:00.0 Off |                    0 |\r\n",
      "| N/A   32C    P0             81W /  400W |     543MiB /  40960MiB |      0%      Default |\r\n",
      "|                                         |                        |             Disabled |\r\n",
      "+-----------------------------------------+------------------------+----------------------+\r\n",
      "                                                                                         \r\n",
      "+-----------------------------------------------------------------------------------------+\r\n",
      "| Processes:                                                                              |\r\n",
      "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\r\n",
      "|        ID   ID                                                               Usage      |\r\n",
      "|=========================================================================================|\r\n",
      "+-----------------------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 859,
   "id": "f2397646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 860,
   "id": "b091f658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from codealltag_data_processor_v2025 import CodealltagDataProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 861,
   "id": "b478b0f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdp_2022 = CodealltagDataProcessor(data_version='20220513', config_path=['codealltag_data_processor.yml'])\n",
    "cdp_2020 = CodealltagDataProcessor(data_version='20200518', config_path=['codealltag_data_processor.yml'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 862,
   "id": "c3d5dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from transformers import (\n",
    "    MT5ForConditionalGeneration,\n",
    "    MT5TokenizerFast,\n",
    "    get_linear_schedule_with_warmup\n",
    ")\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers.optimization import Adafactor, AdafactorSchedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 863,
   "id": "2b630a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(cdp_2022.get_random_seed())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 864,
   "id": "0590c82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class T5FineTuner(pl.LightningModule):\n",
    "    def __init__(self, hparam):\n",
    "        super(T5FineTuner, self).__init__()\n",
    "        self.hparam = hparam\n",
    "\n",
    "        self.model = MT5ForConditionalGeneration.from_pretrained(hparam.model_name_or_path)\n",
    "        self.tokenizer = MT5TokenizerFast.from_pretrained(hparam.model_name_or_path)\n",
    "        self.save_hyperparameters()\n",
    "    \n",
    "    def is_logger(self):\n",
    "        return True\n",
    "\n",
    "    def forward(self, input_ids, attention_mask=None, decoder_input_ids=None, decoder_attention_mask=None, labels=None):\n",
    "        return self.model(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            decoder_input_ids=decoder_input_ids,\n",
    "            decoder_attention_mask=decoder_attention_mask,\n",
    "            labels=labels,\n",
    "        )\n",
    "\n",
    "    def _step(self, batch):\n",
    "        lm_labels = batch[\"target_ids\"]\n",
    "        lm_labels[lm_labels[:, :] == self.tokenizer.pad_token_id] = -100\n",
    "\n",
    "        outputs = self(\n",
    "            input_ids=batch[\"source_ids\"],\n",
    "            attention_mask=batch[\"source_mask\"],\n",
    "            labels=lm_labels,\n",
    "            decoder_attention_mask=batch['target_mask']\n",
    "        )\n",
    "        loss = outputs.loss\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "        self.log('train_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        loss = self._step(batch)\n",
    "        self.log('val_loss', loss, on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        \"Prepare optimizer and schedule (linear warmup and decay)\"\n",
    "\n",
    "        model = self.model\n",
    "        optimizer = Adafactor(model.parameters(), scale_parameter=True, relative_step=True, warmup_init=True, lr=None)\n",
    "        lr_scheduler = AdafactorSchedule(optimizer)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"train\", args=self.hparam)\n",
    "        return DataLoader(train_dataset, batch_size=self.hparam.train_batch_size, drop_last=True, shuffle=True, num_workers=2)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        val_dataset = get_dataset(tokenizer=self.tokenizer, type_path=\"dev\", args=self.hparam)\n",
    "        return DataLoader(val_dataset, batch_size=self.hparam.eval_batch_size, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 865,
   "id": "444fe89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_dict = dict(\n",
    "    model_name_or_path='google/mt5-base',\n",
    "    tokenizer_name_or_path='google/mt5-base',\n",
    "    max_seq_length=512,\n",
    "    learning_rate=3e-4,\n",
    "    weight_decay=0.0,\n",
    "    adam_epsilon=1e-8,\n",
    "    warmup_steps=0,\n",
    "    train_batch_size=2,\n",
    "    eval_batch_size=2,\n",
    "    num_train_epochs=5,\n",
    "    gradient_accumulation_steps=16,\n",
    "    n_gpu=1,\n",
    "    early_stop_callback=False,\n",
    "    fp_16=False,\n",
    "    opt_level='O1',\n",
    "    max_grad_norm=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 866,
   "id": "a0c52a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 9_000\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 867,
   "id": "bc52537b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = cdp_2022.get_train_dev_test_datasetdict_for_sample_size(cdp_2020, sample_size, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "id": "9f806dc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['ID', 'Category', 'FilePath', 'FileSize', 'AnnotationFileExists', 'InputType1', 'InputType2', 'OutputType1', 'OutputType2', '__index_level_0__'],\n",
      "        num_rows: 5760\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['ID', 'Category', 'FilePath', 'FileSize', 'AnnotationFileExists', 'InputType1', 'InputType2', 'OutputType1', 'OutputType2', '__index_level_0__'],\n",
      "        num_rows: 1440\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['ID', 'Category', 'FilePath', 'FileSize', 'AnnotationFileExists', 'InputType1', 'InputType2', 'OutputType1', 'OutputType2', '__index_level_0__'],\n",
      "        num_rows: 1800\n",
      "    })\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "id": "ac16076c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': 4532,\n",
       " 'Category': 'EVENTS',\n",
       " 'FilePath': 'CodEAlltag_pXL_EVENTS/6-/62230.txt',\n",
       " 'FileSize': 176,\n",
       " 'AnnotationFileExists': True,\n",
       " 'InputType1': 'Ich O\\nauch O\\n. O\\nWie O\\ngut O\\ndas O\\ndie O\\nnicht O\\nwissen O\\n, O\\ndas O\\nich O\\nder O\\nHaupttäter O\\nund O\\nDrahtzieher O\\nbin O\\n. O\\nHier O\\nmeine O\\nAdresse O\\n: O\\nNiklaus B-MALE\\nDünnebacke B-FAMILY\\nLöscherstraße B-STREET\\n1 B-STREETNO\\n25985 B-ZIP\\nIbersheim B-CITY\\n-- O\\nTHE O\\nT O\\n☢ O\\n☢ O\\nN O\\n',\n",
       " 'InputType2': 'Ich auch . Wie gut das die nicht wissen , das ich der Haupttäter und Drahtzieher bin . Hier meine Adresse : Niklaus Dünnebacke Löscherstraße 1 25985 Ibersheim -- THE T ☢ ☢ N',\n",
       " 'OutputType1': 'MALE: Niklaus; FAMILY: Dünnebacke; STREET: Löscherstraße; STREETNO: 1; ZIP: 25985; CITY: Ibersheim',\n",
       " 'OutputType2': 'MALE: Niklaus **Ignaz**; FAMILY: Dünnebacke **Pötter**; STREET: Löscherstraße **Vogtstraße**; STREETNO: 1 **0**; ZIP: 25985 **83984**; CITY: Ibersheim **Bollendorf**',\n",
       " '__index_level_0__': 0}"
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "id": "6ed16d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../data/CodEAlltag_pXL_20220513/CodEAlltag_pXL_EVENTS/6-/62230.txt\n",
      "---------------------------------------------------------------------\n",
      "\n",
      "Ich auch. Wie gut das die nicht wissen, das ich der Haupttäter und\n",
      "Drahtzieher bin. Hier meine Adresse:\n",
      "\n",
      "Niklaus Dünnebacke\n",
      "Löscherstraße 1\n",
      "25985 Ibersheim\n",
      "-- \n",
      "THE T☢☢N\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_ = cdp_2022.read_email(dataset['train'][0]['FilePath'], show=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "4575237b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ich auch . Wie gut das die nicht wissen , das ich der Haupttäter und Drahtzieher bin . Hier meine Adresse : Niklaus Dünnebacke Löscherstraße 1 25985 Ibersheim -- THE T ☢ ☢ N'"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['InputType2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "id": "c8d659ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MALE: Niklaus **Ignaz**; FAMILY: Dünnebacke **Pötter**; STREET: Löscherstraße **Vogtstraße**; STREETNO: 1 **0**; ZIP: 25985 **83984**; CITY: Ibersheim **Bollendorf**'"
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['OutputType2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "id": "e2a046ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CodeAlltagDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, tokenizer, dataset, type_path, max_len=512):\n",
    "\n",
    "        self.data = dataset[type_path]\n",
    "        self.max_len = max_len\n",
    "        self.tokenizer = tokenizer\n",
    "        self.tokenizer.max_length = max_len\n",
    "        self.tokenizer.model_max_length = max_len\n",
    "        self.inputs = []\n",
    "        self.targets = []\n",
    "\n",
    "        self._build()\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.inputs)\n",
    "  \n",
    "    def __getitem__(self, index):\n",
    "        source_ids = self.inputs[index][\"input_ids\"].squeeze()\n",
    "        target_ids = self.targets[index][\"input_ids\"].squeeze()\n",
    "\n",
    "        src_mask    = self.inputs[index][\"attention_mask\"].squeeze()\n",
    "        target_mask = self.targets[index][\"attention_mask\"].squeeze()\n",
    "\n",
    "        return {\"source_ids\": source_ids, \"source_mask\": src_mask, \"target_ids\": target_ids, \"target_mask\": target_mask}\n",
    "  \n",
    "    def _build(self):\n",
    "        for idx in range(len(self.data)):\n",
    "            input_, target = self.data[idx][\"InputType2\"], self.data[idx][\"OutputType2\"]\n",
    "      \n",
    "            # tokenize inputs\n",
    "            tokenized_inputs = self.tokenizer.batch_encode_plus(\n",
    "                [input_],\n",
    "                max_length=self.max_len,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            # tokenize targets\n",
    "            tokenized_targets = self.tokenizer.batch_encode_plus(\n",
    "                [target],\n",
    "                max_length=self.max_len,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "\n",
    "            self.inputs.append(tokenized_inputs)\n",
    "            self.targets.append(tokenized_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "id": "9178fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = MT5TokenizerFast.from_pretrained(args_dict['tokenizer_name_or_path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "id": "6d6b2130",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CodeAlltagDataset(tokenizer=tokenizer, dataset=dataset, type_path='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "id": "dbb8f641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ich auch. Wie gut das die nicht wissen, das ich der Haupttäter und Drahtzieher bin. Hier meine Adresse : Niklaus Dünnebacke Löscherstraße 1 25985 Ibersheim -- THE T ☢ ☢ N</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
      "MALE: Niklaus **Ignaz**; FAMILY: Dünnebacke **Pötter**; STREET: Löscherstraße **Vogtstraße**; STREETNO: 1 **0**; ZIP: 25985 **83984**; CITY: Ibersheim **Bollendorf**</s><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
     ]
    }
   ],
   "source": [
    "sample_data = train_dataset[0]\n",
    "print(tokenizer.decode(sample_data[\"source_ids\"], skip_special_tokens=False))\n",
    "print(tokenizer.decode(sample_data[\"target_ids\"], skip_special_tokens=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "id": "e2402596",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s81481/pseugc/lib/python3.9/site-packages/transformers/modeling_utils.py:349: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "args = argparse.Namespace(**args_dict)\n",
    "model = T5FineTuner(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "id": "c4c81f83",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    filename=\"{epoch:02d}-{step:05d}-{val_loss:.4f}\", \n",
    "    monitor=\"val_loss\", \n",
    "    mode=\"min\", \n",
    "    save_top_k=1\n",
    ")\n",
    "class OverrideEpochStepCallback(pl.callbacks.Callback):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "    def on_train_epoch_end(self, trainer: pl.Trainer, pl_module: pl.LightningModule):\n",
    "        self._log_step_as_current_epoch(trainer, pl_module)\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer: pl.Trainer, pl_module: pl.LightningModule):\n",
    "        self._log_step_as_current_epoch(trainer, pl_module)\n",
    "\n",
    "    def _log_step_as_current_epoch(self, trainer: pl.Trainer, pl_module: pl.LightningModule):\n",
    "        pl_module.log(\"step\", trainer.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "id": "b1ac9c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_logger = pl.loggers.TensorBoardLogger('logs/mT5/NER-PG/'+str(sample_size//1000)+'K', name='k' + str(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "id": "a36ce571",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_params = dict(\n",
    "    accumulate_grad_batches=args_dict['gradient_accumulation_steps'],\n",
    "    devices=args_dict['n_gpu'],\n",
    "    max_epochs=args_dict['num_train_epochs'],\n",
    "    precision= '16-mixed' if args_dict['fp_16'] else 32,\n",
    "    gradient_clip_val=args_dict['max_grad_norm'],\n",
    "    callbacks=[OverrideEpochStepCallback(), checkpoint_callback],\n",
    "    accelerator='gpu' if args_dict['n_gpu'] > 0 else 'cpu',\n",
    "    logger=tensorboard_logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "id": "0680dacb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(tokenizer, type_path, args):\n",
    "    tokenizer.max_length = args.max_seq_length\n",
    "    tokenizer.model_max_length = args.max_seq_length\n",
    "    dataset = cdp_2022.get_train_dev_test_datasetdict_for_sample_size(cdp_2020, sample_size, k)\n",
    "    return CodeAlltagDataset(tokenizer=tokenizer, dataset=dataset, type_path=type_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "id": "0b656957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(**train_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "id": "56832d12",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Missing logger folder: logs/mT5/NER-PG/9K/k5\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type                        | Params | Mode\n",
      "-------------------------------------------------------------\n",
      "0 | model | MT5ForConditionalGeneration | 582 M  | eval\n",
      "-------------------------------------------------------------\n",
      "582 M     Trainable params\n",
      "0         Non-trainable params\n",
      "582 M     Total params\n",
      "2,329.605 Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "702812773cf744eaaae629288c674cdb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=5` reached.\n"
     ]
    }
   ],
   "source": [
    "trainer.fit(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "id": "cc525355",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'logs/mT5/NER-PG/9K/k5/version_0/checkpoints/epoch=03-step=00003-val_loss=1.3842.ckpt'"
      ]
     },
     "execution_count": 884,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_dir = f\"logs/mT5/NER-PG/{sample_size//1000}K/k{k}/version_0/checkpoints/\"\n",
    "ckpt_name = next(iter(os.listdir(model_dir)), None)\n",
    "model_path = os.path.join(model_dir, ckpt_name); model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "id": "6b9b7191",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/s81481/pseugc/lib/python3.9/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "/home/s81481/pseugc/lib/python3.9/site-packages/transformers/modeling_utils.py:349: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  return torch.load(checkpoint_file, map_location=\"cpu\")\n"
     ]
    }
   ],
   "source": [
    "model = T5FineTuner.load_from_checkpoint(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "id": "a4accdaf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 1800/1800 [50:43<00:00,  1.69s/it]\n"
     ]
    }
   ],
   "source": [
    "test_dataset = CodeAlltagDataset(tokenizer=tokenizer, dataset=dataset, type_path='test')\n",
    "dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "eval_dataiter = iter(dataloader)\n",
    "\n",
    "model.model.eval()\n",
    "model = model.to(\"cuda\")\n",
    "\n",
    "labels = ['CITY', 'DATE', 'EMAIL', 'FAMILY', 'FEMALE', 'MALE', 'ORG', \n",
    "          'PHONE', 'STREET', 'STREETNO', 'UFID', 'URL', 'USER', 'ZIP']\n",
    "\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "with tqdm(total=len(dataloader), position=0, leave=True) as progress_bar:\n",
    "    for index in range(0, len(dataloader)):\n",
    "        batch = next(eval_dataiter)\n",
    "        input_ids = batch['source_ids'].to('cuda')\n",
    "        attention_mask = batch['source_mask'].to(\"cuda\")\n",
    "        \n",
    "        outs = model.model.generate(input_ids=input_ids,\n",
    "                                    attention_mask=attention_mask,\n",
    "                                    max_length=512,\n",
    "                                    temperature=0.8,\n",
    "                                    do_sample=True,\n",
    "                                    top_k=100)\n",
    "        dec = [\n",
    "            tokenizer.decode(ids, skip_special_tokens=True, clean_up_tokenization_spaces=False).strip()\n",
    "            for ids in outs\n",
    "        ]\n",
    "        \n",
    "        true_labeled_text = dataset[\"test\"][index][\"InputType1\"]\n",
    "        \n",
    "        email_text = cdp_2022.read_email(dataset[\"test\"][index][\"FilePath\"])[1]\n",
    "        predicted_annotation_df = cdp_2022.get_annotation_df_with_input_text_and_predicted_text(email_text,\n",
    "                                                                                                dec[0],\n",
    "                                                                                                labels)\n",
    "        pred_labeled_text = cdp_2022.tokenize_with_somajo_and_annotation_df(email_text, predicted_annotation_df)\n",
    "        \n",
    "        true_list = cdp_2022.get_token_label_tuples(true_labeled_text)\n",
    "        pred_list = cdp_2022.get_token_label_tuples(pred_labeled_text)\n",
    "        \n",
    "        true_label = [item[1] for item in true_list]\n",
    "        pred_label = cdp_2022.align_tags(true_list, pred_list)\n",
    "        \n",
    "        true_labels.append(true_label)\n",
    "        pred_labels.append(pred_label)\n",
    "        \n",
    "        progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 887,
   "id": "83b21939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        CITY     0.9658    0.7635    0.8528       554\n",
      "        DATE     0.9806    0.8306    0.8994       425\n",
      "       EMAIL     0.9863    0.9220    0.9531       705\n",
      "      FAMILY     0.9824    0.9001    0.9394      1611\n",
      "      FEMALE     0.8611    0.8532    0.8571       218\n",
      "        MALE     0.9853    0.9410    0.9627      2425\n",
      "         ORG     0.3564    0.5600    0.4356       175\n",
      "       PHONE     0.9477    0.8164    0.8772       621\n",
      "      STREET     0.9538    0.8664    0.9080       262\n",
      "    STREETNO     0.9916    0.9480    0.9693       250\n",
      "        UFID     0.7640    0.7047    0.7332       193\n",
      "         URL     0.9800    0.8804    0.9275       945\n",
      "        USER     0.5357    0.6522    0.5882        46\n",
      "         ZIP     0.9959    0.9202    0.9565       263\n",
      "\n",
      "   micro avg     0.9474    0.8804    0.9126      8693\n",
      "   macro avg     0.8776    0.8256    0.8471      8693\n",
      "weighted avg     0.9566    0.8804    0.9156      8693\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "from seqeval.metrics import accuracy_score\n",
    "from seqeval.metrics import classification_report\n",
    "from seqeval.scheme import IOB2\n",
    "\n",
    "seqeval = evaluate.load(\"seqeval\")\n",
    "\n",
    "report = classification_report(\n",
    "    y_true=true_labels,\n",
    "    y_pred=pred_labels,\n",
    "    mode=\"strict\",\n",
    "    scheme=IOB2,\n",
    "    zero_division=0,        \n",
    "    output_dict=False,\n",
    "    digits=4\n",
    ")\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "id": "d2e90b3d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'CITY': {'precision': 0.9657534246575342, 'recall': 0.7635379061371841, 'f1-score': 0.8528225806451614, 'support': 554}, 'DATE': {'precision': 0.9805555555555555, 'recall': 0.8305882352941176, 'f1-score': 0.8993630573248407, 'support': 425}, 'EMAIL': {'precision': 0.9863429438543247, 'recall': 0.9219858156028369, 'f1-score': 0.9530791788856305, 'support': 705}, 'FAMILY': {'precision': 0.9823848238482384, 'recall': 0.9000620732464308, 'f1-score': 0.9394233884029803, 'support': 1611}, 'FEMALE': {'precision': 0.8611111111111112, 'recall': 0.8532110091743119, 'f1-score': 0.8571428571428571, 'support': 218}, 'MALE': {'precision': 0.9853195164075993, 'recall': 0.9410309278350516, 'f1-score': 0.9626661041974267, 'support': 2425}, 'ORG': {'precision': 0.3563636363636364, 'recall': 0.56, 'f1-score': 0.43555555555555553, 'support': 175}, 'PHONE': {'precision': 0.9476635514018692, 'recall': 0.8164251207729468, 'f1-score': 0.8771626297577856, 'support': 621}, 'STREET': {'precision': 0.9537815126050421, 'recall': 0.8664122137404581, 'f1-score': 0.908, 'support': 262}, 'STREETNO': {'precision': 0.9916317991631799, 'recall': 0.948, 'f1-score': 0.969325153374233, 'support': 250}, 'UFID': {'precision': 0.7640449438202247, 'recall': 0.7046632124352331, 'f1-score': 0.7331536388140162, 'support': 193}, 'URL': {'precision': 0.9799764428739693, 'recall': 0.8804232804232804, 'f1-score': 0.927536231884058, 'support': 945}, 'USER': {'precision': 0.5357142857142857, 'recall': 0.6521739130434783, 'f1-score': 0.5882352941176471, 'support': 46}, 'ZIP': {'precision': 0.9958847736625515, 'recall': 0.9201520912547528, 'f1-score': 0.9565217391304348, 'support': 263}, 'micro avg': {'precision': 0.9473879673186433, 'recall': 0.8803635108708155, 'f1-score': 0.9126468308389482, 'support': 8693}, 'macro avg': {'precision': 0.8776091657885087, 'recall': 0.8256189856400058, 'f1-score': 0.8471419578023306, 'support': 8693}, 'weighted avg': {'precision': 0.9565903206816602, 'recall': 0.8803635108708155, 'f1-score': 0.9155825710796699, 'support': 8693}}\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(\n",
    "    y_true=true_labels,\n",
    "    y_pred=pred_labels,\n",
    "    mode=\"strict\",\n",
    "    scheme=IOB2,\n",
    "    zero_division=0,        \n",
    "    output_dict=True,\n",
    "    digits=4\n",
    ")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "id": "6415fd71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "844"
      ]
     },
     "execution_count": 889,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = model.to(\"cpu\")\n",
    "del model\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.ipc_collect()\n",
    "import gc\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
