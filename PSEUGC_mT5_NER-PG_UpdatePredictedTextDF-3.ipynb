{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "545bec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from __future__ import annotations\n",
    "from codealltag_data_processor_v2025 import CodealltagDataProcessor\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pandas import DataFrame\n",
    "from pandas.core.series import Series\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, Generator, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a50128",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdp_2022 = CodealltagDataProcessor(data_version='20220513', config_path=['codealltag_data_processor.yml'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c112c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 10_000\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8db06769",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_text_df_name = f'PredictedText_DF_{cdp_2022.get_data_version()}_{sample_size // 1000}K_k{k}.csv'\n",
    "predicted_text_df = pd.read_csv(predicted_text_df_name, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e2fed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['CITY', 'DATE', 'EMAIL', 'FAMILY', 'FEMALE', 'MALE', 'ORG', \n",
    "          'PHONE', 'STREET', 'STREETNO', 'UFID', 'URL', 'USER', 'ZIP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ccb3dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation_df_with_input_text_and_predicted_text(input_text: str, \n",
    "                                                         predicted_text: str,\n",
    "                                                         labels: List[str]) -> DataFrame:\n",
    "    tuples = list()\n",
    "\n",
    "    input_text_length = len(input_text)\n",
    "    input_text_copy = input_text[0: input_text_length]\n",
    "\n",
    "    item_delim = \"; \"\n",
    "    token_delim = \": \"\n",
    "    pseudonym_delim = \" **\"\n",
    "    token_id = 0\n",
    "    next_cursor = 0\n",
    "\n",
    "    predicted_items = predicted_text.split(item_delim)\n",
    "    for item in predicted_items:\n",
    "\n",
    "        label, token, pseudonym = \"\", \"\", \"\"\n",
    "\n",
    "        for l in labels:\n",
    "            if item.startswith(l):\n",
    "                label = l\n",
    "\n",
    "        if label != \"\" and (label+token_delim) in item:\n",
    "\n",
    "            value_splits = item.split(label+token_delim)\n",
    "            token_pseudonym = value_splits[1]\n",
    "\n",
    "            if (pseudonym_delim in token_pseudonym and token_pseudonym.endswith(pseudonym_delim.strip())):\n",
    "\n",
    "                pseudonym_splits = token_pseudonym.split(pseudonym_delim)\n",
    "                token = pseudonym_splits[0]\n",
    "                pseudonym = pseudonym_splits[1][:-2]\n",
    "\n",
    "            else:\n",
    "                token = token_pseudonym\n",
    "\n",
    "            if len(token.strip()) > 0:\n",
    "\n",
    "                start = input_text_copy.find(token)\n",
    "                if start == -1 and ' ' in token:\n",
    "                    start = input_text_copy.find(token.split(' ')[0])\n",
    "                    token = token.replace(' ', '')\n",
    "\n",
    "                if start != -1:\n",
    "                    end = start + len(token)\n",
    "\n",
    "                    token_id += 1\n",
    "                    prev_cursor = next_cursor\n",
    "                    next_cursor += end\n",
    "                    input_text_copy = input_text[next_cursor: input_text_length]\n",
    "\n",
    "                    start = prev_cursor + start\n",
    "                    end = prev_cursor + end\n",
    "\n",
    "                    tuples.append((\n",
    "                        'T' + str(token_id),\n",
    "                        label,\n",
    "                        start,\n",
    "                        end,\n",
    "                        input_text[start:end],\n",
    "                        pseudonym\n",
    "                    ))\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        tuples,\n",
    "        columns=[\"Token_ID\", \"Label\", \"Start\", \"End\", \"Token\", \"Pseudonym\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6dec13ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_adf_and_mT5_original_text_adf(predicted_text_df: DataFrame, \n",
    "                                               idx: int, \n",
    "                                               cdp: CodealltagDataProcessor) -> Dict[str, Tuple]:\n",
    "    \n",
    "    row: Series = predicted_text_df.iloc[idx]\n",
    "    file_path: str = row.FilePath\n",
    "    original_text = cdp.read_email(file_path)[1]\n",
    "    original_adf: DataFrame = cdp.get_annotation_df_by_file(file_path).drop(columns=\"FilePath\")\n",
    "    mT5_predicted_text = row[row.UseVersion]\n",
    "    mT5_original_text_adf = get_annotation_df_with_input_text_and_predicted_text(original_text, mT5_predicted_text, labels)\n",
    "    \n",
    "    return {file_path: (original_adf.to_dict(), mT5_original_text_adf.to_dict())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9aafca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_original_adf_and_mT5_original_text_adf(max_workers: int = 10) -> Generator[Dict[str, Tuple]]:\n",
    "    with tqdm(total=len(predicted_text_df), smoothing=0) as progress_bar:\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = [\n",
    "                executor.submit(get_original_adf_and_mT5_original_text_adf, predicted_text_df, idx, cdp_2022)\n",
    "                for idx in range(0, len(predicted_text_df))\n",
    "            ]\n",
    "            for future in as_completed(futures):\n",
    "                progress_bar.update(1)\n",
    "                yield future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28764be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2000/2000 [00:03<00:00, 512.44it/s]\n"
     ]
    }
   ],
   "source": [
    "merged_dict: Dict[str, Tuple] = {}\n",
    "for result in collect_original_adf_and_mT5_original_text_adf():\n",
    "    merged_dict.update(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a632ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_text_df[['OriginalADF', 'MT5_OriginalTextADF']] = np.array(\n",
    "    [merged_dict.get(file_path) for file_path in predicted_text_df['FilePath']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6343b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_text_df.to_csv(predicted_text_df_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
