{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "545bec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from __future__ import annotations\n",
    "from codealltag_data_processor_v2025 import CodealltagDataProcessor\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pandas import DataFrame\n",
    "from pandas.core.series import Series\n",
    "from tqdm import tqdm\n",
    "from typing import Any, Dict, Generator, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33a50128",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdp_2022 = CodealltagDataProcessor(data_version='20220513', config_path=['codealltag_data_processor.yml'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c112c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 10_000\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8db06769",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_text_df_name = f'PredictedText_DF_{cdp_2022.get_data_version()}_{sample_size // 1000}K_k{k}.csv'\n",
    "predicted_text_df = pd.read_csv(predicted_text_df_name, index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e2fed52",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['CITY', 'DATE', 'EMAIL', 'FAMILY', 'FEMALE', 'MALE', 'ORG', \n",
    "          'PHONE', 'STREET', 'STREETNO', 'UFID', 'URL', 'USER', 'ZIP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ccb3dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_annotation_df_with_input_text_and_predicted_text(input_text: str, \n",
    "                                                         predicted_text: str,\n",
    "                                                         labels: List[str]) -> DataFrame:\n",
    "    tuples = list()\n",
    "\n",
    "    input_text_length = len(input_text)\n",
    "    input_text_copy = input_text[0: input_text_length]\n",
    "\n",
    "    item_delim = \"; \"\n",
    "    token_delim = \": \"\n",
    "    pseudonym_delim = \" **\"\n",
    "    token_id = 0\n",
    "    next_cursor = 0\n",
    "\n",
    "    predicted_items = predicted_text.split(item_delim)\n",
    "    for item in predicted_items:\n",
    "\n",
    "        label, token, pseudonym = \"\", \"\", \"\"\n",
    "\n",
    "        for l in labels:\n",
    "            if item.startswith(l):\n",
    "                label = l\n",
    "\n",
    "        if label != \"\" and (label+token_delim) in item:\n",
    "\n",
    "            value_splits = item.split(label+token_delim)\n",
    "            token_pseudonym = value_splits[1]\n",
    "\n",
    "            if (pseudonym_delim in token_pseudonym and token_pseudonym.endswith(pseudonym_delim.strip())):\n",
    "\n",
    "                pseudonym_splits = token_pseudonym.split(pseudonym_delim)\n",
    "                token = pseudonym_splits[0]\n",
    "                pseudonym = pseudonym_splits[1][:-2]\n",
    "\n",
    "            else:\n",
    "                token = token_pseudonym\n",
    "\n",
    "            if len(token.strip()) > 0:\n",
    "\n",
    "                start = input_text_copy.find(token)\n",
    "                if start == -1 and ' ' in token:\n",
    "                    start = input_text_copy.find(token.split(' ')[0])\n",
    "                    token = token.replace(' ', '')\n",
    "\n",
    "                if start != -1:\n",
    "                    end = start + len(token)\n",
    "\n",
    "                    token_id += 1\n",
    "                    prev_cursor = next_cursor\n",
    "                    next_cursor += end\n",
    "                    input_text_copy = input_text[next_cursor: input_text_length]\n",
    "\n",
    "                    start = prev_cursor + start\n",
    "                    end = prev_cursor + end\n",
    "\n",
    "                    tuples.append((\n",
    "                        'T' + str(token_id),\n",
    "                        label,\n",
    "                        start,\n",
    "                        end,\n",
    "                        input_text[start:end],\n",
    "                        pseudonym\n",
    "                    ))\n",
    "\n",
    "    return pd.DataFrame(\n",
    "        tuples,\n",
    "        columns=[\"Token_ID\", \"Label\", \"Start\", \"End\", \"Token\", \"Pseudonym\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bfe4c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pseudonymized_text(input_text: str, predicted_annotation_df: DataFrame) -> str:\n",
    "    output_text = input_text\n",
    "    offset = 0\n",
    "    for index, row in predicted_annotation_df.iterrows():\n",
    "        output_text = output_text[:(row.Start+offset)] + row.Pseudonym + output_text[(row.End+offset):]\n",
    "        offset += len(row.Pseudonym) - len(row.Token)\n",
    "    return output_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dec13ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_version_and_pseudonymized_text(predicted_text_df: DataFrame, \n",
    "                                          idx: int, \n",
    "                                          cdp: CodealltagDataProcessor) -> Dict[str, Tuple]:\n",
    "    \n",
    "    row: Series = predicted_text_df.iloc[idx]\n",
    "    file_path: str = row.FilePath\n",
    "    input_text: str = cdp.read_email(file_path)[1]\n",
    "    true_adf: DataFrame = cdp.get_annotation_df_by_file(file_path)\n",
    "    label_token_list: List[str] = true_adf[['Label', 'Token']].agg('-'.join, axis=1).tolist()\n",
    "    versions: List[str] = [col for col in predicted_text_df.columns if re.match(r'^V\\d+$', col)]\n",
    "    version_match_dict: Dict[str, Any] = dict()\n",
    "    for version in versions:\n",
    "        version_adf: DataFrame = get_annotation_df_with_input_text_and_predicted_text(input_text, row[version], labels)\n",
    "        v_label_token_list: List[str] = version_adf[['Label', 'Token']].agg('-'.join, axis=1).tolist()\n",
    "        match_count: int = 0\n",
    "        for item in label_token_list:\n",
    "            if item in v_label_token_list:\n",
    "                label: str = item.split('-', 1)[0]\n",
    "                token: str = item.split('-', 1)[1]\n",
    "                pseudonym: str = version_adf.loc[\n",
    "                    (version_adf['Label'] == label) & (version_adf['Token'] == token)\n",
    "                ].iloc[0].Pseudonym\n",
    "                if token != pseudonym:\n",
    "                    match_count += 1\n",
    "        priority: str = 'low'\n",
    "        if label_token_list == v_label_token_list:\n",
    "            priority = 'high'\n",
    "        version_match_dict[version] = {'priority': priority, 'count': match_count, 'adf': version_adf}\n",
    "\n",
    "    has_high: bool = any(v['priority'] == 'high' for v in version_match_dict.values())\n",
    "    if has_high:\n",
    "        filtered: Dict[str, Any] = {k: v for k, v in version_match_dict.items() if v['priority'] == 'high'}\n",
    "    else:\n",
    "        filtered = version_match_dict.copy()\n",
    "    max_count: int = max(v['count'] for v in filtered.values())\n",
    "    candidates: List[str] = [k for k, v in filtered.items() if v['count'] == max_count]\n",
    "    selected_version: str = random.Random(cdp.get_random_seed()).choice(candidates)\n",
    "    pseudonymized_text: str = get_pseudonymized_text(input_text, version_match_dict[selected_version]['adf'])\n",
    "    \n",
    "    return {file_path: (selected_version, pseudonymized_text)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9aafca54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_pseudonymized_texts(max_workers: int = 10) -> Generator[Dict[str, Tuple]]:\n",
    "    with tqdm(total=len(predicted_text_df), smoothing=0) as progress_bar:\n",
    "        with ThreadPoolExecutor(max_workers=max_workers) as executor:\n",
    "            futures = [\n",
    "                executor.submit(select_version_and_pseudonymized_text, predicted_text_df, idx, cdp_2022)\n",
    "                for idx in range(0, len(predicted_text_df))\n",
    "            ]\n",
    "            for future in as_completed(futures):\n",
    "                progress_bar.update(1)\n",
    "                yield future.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28764be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████| 2000/2000 [00:33<00:00, 59.57it/s]\n"
     ]
    }
   ],
   "source": [
    "merged_dict: Dict[str, Tuple] = {}\n",
    "for result in collect_pseudonymized_texts():\n",
    "    merged_dict.update(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a632ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_text_df[['UseVersion', 'PseudonymizedText']] = np.array(\n",
    "    [merged_dict.get(file_path) for file_path in predicted_text_df['FilePath']]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6343b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_text_df.to_csv(predicted_text_df_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
